% ettdoc.tex V2.10, 19 June 2012

\documentclass[times]{ettauth}
\usepackage[toc,page]{appendix}
\usepackage{moreverb}

\usepackage[colorlinks,bookmarksopen,bookmarksnumbered,citecolor=red,urlcolor=red]{hyperref}

\newcommand\BibTeX{{\rmfamily B\kern-.05em \textsc{i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\def\volumeyear{2017}

\newcommand{\eg}{e.g., }
\newcommand{\ie}{i.e., }
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\usepackage{times}
%\usepackage{mathptmx}
\usepackage{mathtools}
\usepackage[draft,nomargin,marginclue,footnote,silent]{fixme}
\setcounter{tocdepth}{2} %table of contents


\theoremstyle{mytheoremstyle}
\newtheorem{theorem}{Theorem}[section]

\theoremstyle{mytheoremstyle}
\newtheorem{corollary}{Corollary}[section]

\theoremstyle{mytheoremstyle}
\newtheorem{lemma}{Lemma}[section]

\newtheorem{mydef}{Definition}

\DeclareMathOperator*{\Max}{Max}
\DeclareMathOperator*{\Min}{Min}

\newcommand{\bigO}{\ensuremath{\mathcal{O}}}% big-O notation/symbol
\usepackage{subfigure}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{lipsum}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{wide=\parindent}
\usepackage[referable]{threeparttablex}
\renewlist{tablenotes}{enumerate}{1}
\makeatletter
\setlist[tablenotes]{label=\tnote{\alph*},ref=\alph*,itemsep=\z@,topsep=\z@skip,partopsep=\z@skip,parsep=\z@,itemindent=\z@,labelindent=\tabcolsep,labelsep=.2em,leftmargin=*,align=left,before={\footnotesize}}
\makeatother

\usepackage{graphicx}
\usepackage{sidecap}
\usepackage{kantlipsum} %<- For dummy text
\usepackage{mwe} %<- For dummy images
\usepackage{multirow}
\usepackage{multicol}

%% Andere Packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{a4wide} %%Kleinere Seitenränder = mehr Text pro Zeile.
\usepackage{fancyhdr} %%Fancy Kopf- und Fußzeilen
%\usepackage{longtable} %%Für Tabellen, die eine Seite überschreiten
\usepackage{lscape}
\usepackage{rotating}
%\usepackage[htt]{hyphenat} %Trennung von Typewriter-Schriften
%\usepackage{listings}
%\usepackage{pstricks-add} --> This package generates problems with booktabs (toprule, etc.)
\usepackage[autostyle]{csquotes}
\usepackage{amsmath,bm}
\usepackage{array}
% Tabellen mit Center und left
\usepackage{tabularx,colortbl} % colored table background
%\usepackage{tablefootnote}
\newcolumntype{C}[1]{>{\centering\arraybackslash}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}m{#1}}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}m{#1}}
% Table spacings
\newcommand\T{\rule{0pt}{2.5ex}\rule[-1.0ex]{0pt}{0pt}}
\newcommand\B{\rule[-1.0ex]{0pt}{0pt}}


\definecolor{slightgray}{gray}{.90}
\usepackage{rotating}
\usepackage{hhline}
\usepackage{float}
\usepackage{caption}% http://ctan.org/pkg/caption
\captionsetup[table]{format=plain,labelformat=simple,labelsep=period}
%\usepackage{authblk}

\usepackage{color}

\begin{document}

%\runningheads{A.~N.~Other}{A demonstration of the \journalabb\
%class file}

\articletype{RESEARCH ARTICLE}

\title{Robust Clustering for Ad Hoc Cognitive Radio Network}
%\author[1]{Di Li\thanks{li@umic.rwth-aachen.de}}
%\author[2]{Erwin Fang\thanks{xx}}
%\author[3]{James Gross}
\author{Di Li\textsuperscript{1}\corrauth, Erwin Fang\textsuperscript{2}, James Gross\textsuperscript{3}}
%\affil[1]{RWTH Aachen University}
%\affil[2]{ETH Zurich}
%\affil[3]{KTH Royal Institute of Technology}
\address{RWTH Aachen University\textsuperscript{1}, Swisscom (Schweiz) AG\textsuperscript{2}, KTH Royal Institute of Technology\textsuperscript{3} }
%\renewcommand\Authands{ and }
%\corraddr{Communication Theory Lab
%School of Electrical Engineering, 
%KTH Royal Institute of Technology
%SE - 100 44 Stockholm\\Email: james.gross@ee.kth.se}
\corraddr{Chair of Communication and Distributed Systems
Ahornstrasse 55 - building E3
52074 Aachen
Germany
\\Email: li@umic.rwth-aachen.de}




\begin{abstract}
Cluster structure in cognitive radio networks facilitates cooperative spectrum sensing, routing and other functionalities.
Unlicensed channels, which are temporally available for a group of cognitive radio users in one area, consolidate the group into a cluster.
More available unlicensed channels in a cluster make the cluster more likely to uphold against the licensed users' influence, making clusters more robust.
This paper analyses the problem of how to form robust clusters in a cognitive radio network such that cognitive radio systems benefit from collaboration within clusters despite intense primary user activity.
%In the process of forming clusters, every secondary user decides with whom to form a cluster, or which cluster to join.
We give a formal description of the robust clustering problem, prove it to be NP-hard and propose both centralized and distributed solutions.
The congestion game model is adopted to analyze the process of cluster formation, which not only contributes to the design of the distributed clustering scheme, but also provides a guarantee on the convergence to a Nash equilibrium and the convergence speed.
%Our proposed clustering solution is versatile to fulfill some other requirements such as faster convergence and cluster size control.
The proposed distributed clustering scheme outperforms state-of-the-art related works in terms of cluster robustness, convergence speed and overhead.
%Besides, we prove the clustering problem is NP-hard, and also propose the centralized solution.
Extensive simulations are presented supporting the theoretical claims.
\end{abstract}

%\keywords{class file; \LaTeXe; \emph{\journalabb}}

\maketitle
\graphicspath{
{../figures/04_clutering/}
}

\section{Introduction}
\label{intro}
%CR concept
Cognitive radio (CR) is a promising technology to solve the spectrum scarcity problem for the upcomging era of internet of things~\cite{Mitola, Rawat20161}.
Licensed users access the spectrum allocated to them whenever there is information to be transmitted.
In contrast, as one way, unlicensed users can access the spectrum via opportunistic spectrum access, \ie they access the licensed spectrum only after validating the channel is unoccupied by licensed users, where spectrum sensing~\cite{sensing_survey_2009} plays an important role in this process.
In this hierarchical spectrum access model~\cite{zhao_survey_DSA_2007}, the licensed users are also called primary users (PU), while the unlicensed users are referred to as secondary users and constitute a so called cognitive radio network (CRN).
%cluster
For CRN, accurate spectrum sensing is critical, and the rate of false negative \ie misdetecting the active primary users, should be minimized~\cite{Sahai_FundamentalDesignTradeoffs2006}.
Cooperative spectrum sensing, which relies on the consensus of CR users within a certain area\footnote{The terms user and node appear interchangeably in this paper. In particular, user is adopted when its networking or cognitive ability are discussed or stressed, while we refer to nodes typicallly in the context of the network topology.}, has been shown to improve spectrum sensing accuracy with the presence of noise uncertainty and channel fading~\cite{Jacob2012, coorperativeSensing_Akyildiz11}.
%C3
In this regard, clustering is regarded as an effective method to realize cooperative spectrum sensing~\cite{Sun07_clustering_spectrum_secsing}.
% ... decreases considerably the negative probability due to the random channel effects like fading and shadowing.

Clustering is the process of grouping certain users in geographic proximity into a collective.
% and as an effective technique, it is proposed with the emergence of mobile wireless networks~\cite{gerla_97} and there has been a plethora of clustering schemes.
As to wireless networks where no restriction is imposed on nodes to access the spectrum, \ie 
wireless ad-hoc, mesh networks and sensor networks, clustering the network helps to decrease the transmission power consumption~\cite{Kawadia03},  improve the routing performance~\cite{clustering_mesh_globecom2010}, or imrove the network lifetime and coverage~\cite{Abbasi_survey_07}.
%In CRN, clusters are formed in the very beginning of the network operation, and re-formed periodically according to the dynamics of the CRN.
For cognitive radio netowrks, the formed clusters help the participating nodes improve spectrum sensing accuracy.
Besides, clusters benefit channel switching when primary users are detected by at least one secondary user in that cluster, then all the cluster members can stop payload transmissions swiftly and vacate the operating channel ~\cite{willkomm08}.
Clustering also benefits the operation of a CRN by reducing the interference between cognitive clusters~\cite{centralizedSharing80222}, and supporting routing~\cite{Abbasi_survey_07}.
%As to the coexistence of CR users, they can be notified by cluster head (CH) or other cluster members about the possible collision, the possibility for them to interfere neighbouring clusters is reduced~\cite{centralizedSharing80222}. 
%Except for benefiting the dynamic spectrum sharing in CRN, clustering contributes to the other wireless networks in many aspects~\cite{Kawadia03, clustering_mesh_globecom2010, Abbasi_survey_07}.

In CRN, a formed cluster seizes one or multiple unlicensed channels which are available for every CR node in that cluster.
In this paper available unlicensed channels are called \textit{common licensed channels} (or common channels for short, which is abbreviated as CC).
The availability of CCs within a cluster decides the existence of that cluster, \ie if no CCs are available then the corresponding cluster does not exist.
In a cluster, both payload and control overheads can be transmitted on the CCs.
When one or several cluster members can not access a certain CC because primary user's activity is detected on that channel, the channel will be excluded from the set of CCs.
In particular, if that channel is being used for payload communication, the communication pair will stop and resume transmission on another available CC.
The activity of primary users is usually unknown to the secondary users, thus deemed as random to secondary users.
Consequently, a cluster which secures more CCs will be more robust to random primary user activities and anticipate a longer life expectancy. 
In this paper, the robustness of clusters is their ability to uphold with the influence of active primary users.
The robust clustering enables more secondary users to reside in the resulting clusters when the available spectrum becomes scarcer.
%

%As long as there is a CC available, the corresponding cluster can continue to exchange payload data.


Cluster size is inherently correlated with the cluster robustness.
Given a CRN, it is obvious that getting rid of certain secondary users from a cluster may yield more CCs.
However, this contradicts to one of the motivations of clustering, \ie the cooperative decision making, where in general more users result in more accurate sensing results~\cite{Consensus_based_clustering12}.
Thus the number of small clusters, especially the \textit{singleton clusters}, \ie the cluster which has only one CR node, should be minimized.
On the other hand, as to the cluster which consists of many nodes, although the spectrum sensing is benefited, there is usually only a small number of CCs.
Thus big cluster undermines the robustness of the cluster against primary users' activity.
Thus, the cluster robustness discussed in terms of number of CCs carries little meaning when the sizes of formed clusters are not considered.
Cluster size also plays a role in transmission power consumption, \ie cluster size affects the transmission power consumption when routing is conducted~\cite{clustering_globecom11, EnergyEfficientClusteringRouting_2015}.

In this paper robust clustering in CRN is analyzed as a mathematical problem and proved to be NP-hard, then both centralized and distributed schemes are proposed.
We propose an alternate metric to measure cluster robustness in contrast to previous works~\cite{Li11_ROSS} and~\cite{LIU_TMC11_2}.
We claim cluster robustness can not be indicated merely by the average number of CCs of clusters, but by the ability of the clusters to uphold when the primary users' activity becomes more active.
In this paper, we identify the robustness of clusters by the number of unclustered CR nodes.
We also consider the necessity of cluster size control and its influence on cluster robustness.
The propsoed distributed schemes extend our previous work ROSS (Robust Spectrum Sharing)~\cite{Li11_ROSS} by involving cluster size control.
%Our distributed schemes solve the size divergence problem in clusters as discussed in~\cite{Li11_ROSS} and~\cite{LIU_TMC11_2}.
%Besides, our proposed distributed schemes are still suitable for the scenario where fast deployment is desired.
Throughout this paper, we call the proposed distributed schemes the \textit{variants of ROSS}.
 
%
%
The rest of the paper is organized as follows. 
In section~\ref{related_work}, we introduce the clustering techniques in CRN and those focusing on robustness.
The relation between this paper and work in~\cite{Li11_ROSS} is elaborated.
The system model and the robust clustering problem formulation are presented in Section~\ref{sec:model}. 
The centralized and distributed solutions are introduced in Section~\ref{centralized_solution} and~\ref{ross} respectively.
%The clustering problem is given through analysis and a centralized scheme is proposed in section~\ref{centralized_scheme}.
Extensive performance evaluation is given in Section~\ref{performance}.
Our work is concluded in Section~\ref{conclusion}.



\section{Related Work}
\label{related_work}
In the following we give a brief review on the clustering in CRN, with emphasis on the theme of robust clustering.
%%[crn for clustering] 
%%due to attenuation of signal propagation, primary users can only be detected by CR users when they locate closely to CR users.
%In cognitive radio networks, secondary users which locate closely with each other are possibly affected by the same group of primary users, so that the availability of licensed spectrum is similar to them, \ie certain channels are available on each of them.
%The similarity of available spectrum on a group of neighbouring CR nodes, along with the benefit of collaborative decision among multiple nodes, leads to clustering as an effective approach for many applications.
%[robustness issue for clustering]
%%%%%%%%%%%
%On the other hand, large clusters are not preferred in some scenarios neither, \eg for the CRN composed with resource limited users, managing the cluster members in a large cluster is a substantial burden. 
%Hence, the cluster size should fall in a desired range according to different application scenarios~\cite{Chen04clusteringalgorithms, capacity_cluster_06}.
%%%%%%%%%%%%
%with the intention to provide a robust infrastructure for the applications which may be conducted above that in CRN.
%that being said, when we design this clustering scheme in CRN, we do consider the services to be delivered by the network.
%Cluster sizes affect the power consumption directly in wirelss sensor networks~\cite{clustering_globecom11, EnergyEfficientClusteringRouting_2015}.
%When the cluster size is not deliberately discussed, it is also decided alongside the optimization of the network, \eg the opimal selection of the aggregation points in a wireless sensor network results in the clusters~\cite{data_aggr_algorithm_04}.
%%%%%%%%%%%%%
%Various clustering schemes are proposed to target different aspects in cognitive radio networks.
%Work~\cite{Consensus_based_clustering12} improves spectrum sensing ability by grouping the CR users with potentially best detection performance into the same cluster.
%Clustering scheme~\cite{clustering_globecom11} obtains the best cluster size which minimizes power consumption caused by communication within and among clusters.
%\cite{clustering_globecom11} proposes clustering strategy in cognitive radio network, which looks into the relationship between cluster size and power consumption and accordingly controlling the cluster size to decrease power consumption.
With regard to forming clusters in CRN, deciding on the common channel within each cluster is the foremost question to answer.
\cite{Zhao07, Chen07,Affinity_clustering_09icccn} propose the clustering schemes and enforce that every cluster possesses at least one CC.
Clustering scheme~\cite{Consensus_based_clustering12} looks for a network partition which improves the accuracy of spectrum sensing with the cluster structure.
%Clustering scheme~\cite{clustering_globecom11} obtains the best cluster size which minimizes power consumption caused by communication within and among clusters.
\cite{TWC2012_cooperative_communication} forms the clusters by deciding on the cluster heads, where the transmit power for the long-haul transmission between the cluster heads is minimized.
\cite{clustering_globecom11} proposes a cluster structure which promises energy efficiency.
\cite{cluster_EW10} proposes strategy on how to decide on the CCs and access the multiple CCs within clusters.
An event-driven clustering scheme is proposed for cognitive radio sensor networks in \cite{Ozger_cluster_crsn_13}.
None of the above mentioned schemes provides a certain robustness to formed clusters against primary users. 

The authors of~\cite{Mansoor2015} propose a clustering algorithm which aims to speed up the process of re-clustering in case a cluster doesn't uphold in front of active primary users.
However, this work does not consider cluster robustness and messaging overhead during frequent re-clustering processes.
A distributed clustering scheme~\cite{LIU_TMC11_2} (denoted as SOC) is proposed, which is designed to generate clusters which  have multiple CCs.
The authors compared SOC with other schemes in terms of the average number of CCs of the formed cluster, where SOC outperforms other schemes by 50\%-100\%. 
Note that SOC's comparison schemes are designed either for ad hoc network without consideration of channel availability~\cite{Basagni99}, or for CRN but just considering connection among CR nodes~\cite{Zhao07}. 
%The robustness of the clusters comes from the multiple CCs available for the clusters.
%SOC involves three phases of distributed executions.
In the first phase of SOC, every secondary user forms clusters with some one-hop neighbors. 
In the second and final phase, each secondary user seeks to either merge other clusters or join one of them.
The product of the number of CCs and cluster size is adopted as the metric by each secondary user in every phase. 
The drawbacks of this scheme are as follows: although the adopted metric considers both the cluster size and the number of CCs, cluster formation can be easily dominated by only one factor.
For example, a node which accesses abundant channels may form a cluster by itself and doesn't have motivation to unite neighboring nodes to form a cluster.
In addition, this scheme leads to the high variance of the cluster sizes, which is not desired in certain applications as discussed in~\cite{clustering_globecom11, cluster_EW10}.
\cite{mansoor_15_cluster_robust} presents a heuristic method to form clusters. Although the authors claim that robustness is one goal to achieve, the minimum number of clusters is finally pursued.
%
In~\cite{Li11_ROSS} we propose a distributed clustering scheme ROSS (Robust Spectrum Sharing) under a game theoretic framework. 
Compared with the clustering schemes introduced above, the clusters are formed faster and the clusters possess more CCs than SOC.
However, as all the other clustering schemes, this scheme does not have control over formation of the very small or very large clusters which are not desirable.
Furthermore, both this work and SOC define robustness just to be the number of CCs per cluster, and don't consider the sustainability of clusters against increasing activity of primary users, leaving the issue of cluster robustness open.
%






\section{System Model and Problem Formulation}
\label{sec:model}

We consider a set of CR users $\mathcal{N}$ and a set of primary users distributed over a given area.
A set of licensed channels $\mathcal{K}$ is available for the primary users. 
The CR users are allowed to transmit on channel $k \in \mathcal{K}$ only if no primary user is detected to be working at their locations on channel $k$. 
CR users conduct spectrum sensing independently and sequentially on all licensed channels.\footnote{We assume that every node can detect the presence of an active primary user on each channel with certain accuracy. The spectrum availability can be validated with a certain probability of detection. Spectrum sensing/validation is out of the scope of this paper.}
We adopt the unit disk model~\cite{unitDiskModel} for both primary and CR users' transmission.
If a CR node $i$ locates within the transmission range of an active primary user $p$, $i$ is not allowed to use the channel which is being used by $p$.
We assume the primary users change their operation channels slowly, thus we omit the time index when denoting spectrum availability. 
As the result of spectrum sensing, $K_i \subseteq \mathcal{K}$ denotes the set of available licensed channels for CR user $i$.
As the transmission range of primary users is limited and CR users have different locations, different CR users have different views of the spectrum availability, i.e., for any $i, j \in \mathcal{N}$, $K_i$ equals $K_{j}$ does not necessarily hold.
We therefore represent the network of CR nodes by a graph $G = (\mathcal{N}, E)$, where $E \subseteq \mathcal{N} \times \mathcal{N}$ such that $\{i, j\} \in E$ if and only if $K_{i} \cap K_{j}\neq \emptyset$ and $d_{i,j} < r$, where $d_{i,j}$ is the distance between $i, j$ and $r$ is the radius of CR user's transmission range. 
%
Among the CR users, we denote by $\text{Nb}(i)$ the neighborhood of $i$, which consists of the CR nodes located within $i$'s transmission range. 

We assume there is one dedicated control channel which is used to exchange signaling messages during the clustering process.
This control channel could be one of the ISM bands or other reserved spectrum which is exclusively used for transmitting control messages.\footnote{Actually, the control messages involved in the clustering process can also be transmitted on the available licensed channels through a rendezvous process by channel hopping~\cite{channelHopping_Rendezvous_2014, Gu_distributed_rendezvous_2014}, i.e., two neighboring nodes establish communication on the same channel.}
Over the control channel, a secondary user $i$ can exchange its spectrum sensing result $K_i$ with all its one hop neighbors $\text{Nb}(i)$.
In the following, we refer to licensed channels as channels in general, and will explicitly mention the dedicated control channel if necessary. 

Here we give the description of cluster in CRN. 
A cluster $C$ is a set of secondary nodes in an area, and there is a set of common channels which are available for each node.
Besides, a cluster consists of a cluster head $h(C)$ and a number of cluster members.
The cluster head is able to communicate with any cluster member directly.
Our scheme enables the cluster heads to be selected in a distributed manner, and a cluster can only be formed only by these selected cluster head.
%C1-4
%$\text{Nb}(i)$ denotes node $i$'s neighborhood which consists of all its one hop neighbors.
%For any cluster member $i \in C$, $i \in \text{Nb} (h_C) $ holds.
The size of $C$ is denoted by $|C|$.
When the cluster head of a cluster is $i$, we denote that cluster by $C(i)$.
$K(C)$ denotes the set of CCs in cluster $C$, $ K(C) = \bigcap_{i\in C} K_i$.
%Clustering is performed periodically, because the secondary users are mobile and the primary users change their operation channels, thus the channel availability on secondary users changes accordingly.
The notations used in the system model are listed in Table~\ref{tab1}.
\begin{table}[h!]
\caption{Notations}
\label{tab1}
\centering
\begin{tabular}{llr}
\toprule
Symbol & Description \\
\midrule
$\mathcal{N}$  & set of CR users in a CRN\\
$N$ & number of CR users in a CRN, $N=|\mathcal{N}|$\\
$\mathcal{K}$	& set of licensed channels\\
$k(i)$ & the working channel of user $i$\\
$\text{Nb}(i)$ & the neighborhood of CR node $i$    \\
$C(i)$ & a cluster whose cluster head is $i$  \\
$K_i$   & the set of available channels at CR node $i$  \\
$K(C(i))$   & the set of available CCs of cluster $C(i)$ \\
%$h(C)$ & cluster head of a cluster $C$\\
$h(C)$ & the cluster head of a cluster C\\
%$\text{CH}$ & cluster head\\
%$\text{CH}$ & cluster head\\
$\delta$ & the cluster size which is preferred\\
$S_i$ & a set of claiming clusters, each of which includes \\
& debatable node $i$ after phase I\\
$d_i$  & individual connectivity degree of CR node $i$\\
$g_i$  & neighborhood connectivity degree of CR node $i$\\
$f(C)$ & the number of CCs of a cluster $C$, which is used \\
& in the problem description\\
% $\mathcal{G}$ & a collection of some possible clusters in $\mathcal{N}$\\
 $\mathcal{S}$ & the collection of all the possible clusters in $\mathcal{N}$\\
 $C_i$  & the $i$-th cluster in $\mathcal{S}$ \\
 $|C_i|$ & size of the cluster $C_i$\\
 $|K(C_i)|$ & the number of CCs of cluster $C_i$\\
 $n$ & the number of debatable nodes\\
 $m$ & the number of claiming cluster heads\\
\bottomrule
\end{tabular}
\end{table}



\subsection{Robust Clustering Problem in CRN}
\label{problem}

As introduced in Section~\ref{intro}, robustness of the clusters is their ability to uphold with the influence of the active primary users, and it is represented by the number of secondary users which are not included in any cluster.
To achieve better robustness, we propose that cluster should be formed by increasing the number of CCs.
Meanwhile, the sizes of the formed clusters should be regulated, \ie they don't diverge from the desired cluster size greatly.



\begin{mydef}
\label{def_centralized_clustering}
\textit{Robust clustering problem in CRN.}

As to a cognitive radio network where the set of CR nodes is $\mathcal{N}$, the robust clustering problem is to decide the set of clusters $\mathcal{T}$, where 
\begin{enumerate}
\setlength{\itemindent}{.05in}
\item the intersection of any two clusters in $\mathcal{T}$ is an empty set
\item the union of clusters in $\mathcal{T}$ is $\mathcal{N}$
\item when the number of common channels for cluster $C$ is denoted as $f(C)$, the sum of the $f(C)$ is the maximal, where $C\in \mathcal{T}$ and meanwhile the cluster sizes fall in the scope $\big[\delta_1, \delta_2\big]$.
$\delta_1, \delta_2\in \mathbb{Z}^+$ and $\delta_1 \leq \delta_2$.
When the cluster size is out of $\big[\delta_1, \delta_2\big]$, $f(C)$ is defined as 0.

\item the size of $C$ in $\mathcal{T}$ is allowed to be 1.
%, and $\delta$ is decided according to the application to be implemented in the CRN.
\end{enumerate}
\end{mydef}

The decision version of this problem is to determine whether there exists a set of clusters, say $\mathcal{X}$, so that $\cup C_{C\in\mathcal{X}} = \mathcal{N}$, and $\sum_{C\in \mathcal{X}} f(C) \geqslant \lambda$ where $\lambda$ is a real number.
We have the following theorem on the problem's complexity.
\begin{theorem}
\label{theorem1}
The robust clustering problem in CRN is NP-hard, when $\delta_1=2$ and $\delta_2 > 3$.
%when the maximum size of clusters is larger than 3
%Assume a CRN can be represented by a connected graph, and there is at least one common channel between any pair of neighbours, then forming at least two CR nodes into one cluster is NP-complete.
\end{theorem}
The proof is in Appendix~\ref{proof_theorem1}.

\section{Centralized Solution for Robust Clustering}
\label{centralized_solution}
When the global knowledge of the CRN \ie the locations of primary users and their working channels, and the locations of secondary users and available channels on them, we can propose a centralized scheme.
We obtain the set of $\mathcal{S}$ which contains all the clusters in $\mathcal{N}$, \ie $\mathcal{S}=\{C_1, C_2,\ldots,C_i, \ldots, C_{|\mathcal{S}|}\}$ \footnote{The subscript $i$ means the $i$-th cluster in $\mathcal{S}$.} and there is $\bigcup_{1\leq i \leq |\mathcal{S}|} C_i = \mathcal{N}$.
The proposed centralized solution formulates the problem in Definition~\ref{def_centralized_clustering} as an optimization problem which is solved with standard software packages.
The optimization decides on the clusters according to the following optimization formulation, which is a binary linear programming problem and can be solved by many available solvers.

 

\begin{equation}
\begin{aligned}
     &\max\limits_{y_i, x_{ij}} && \Sigma_{j=1}^N\Sigma_{i=1}^M (y_i\cdot t_{ij}) \\
     &\text{subject to}   && \Sigma_{i=1}^M x_{ij} = 1, for\,\,\forall j=1, \ldots, N \\
   &&& \Sigma_{j=1}^N x_{ij} = |C_i|\cdot y_i,\, for\,\,\forall i=1, \ldots, M \\
  % &&& \text{$x_{ij}$ and $w_i$ are binary variables.}\\
   &&& i\in \{1,2, \cdots M\}, \hspace{0.3cm} j\in \{1,2,\cdots N\}
%\notag
\end{aligned}
\label{centralized_opt}
\end{equation}
$y_i$ and $x_{ij}$ are two binary variables.
% where $j\in \{1,2,\cdots,N-1, N\}$ and $i\in \{1,2,\cdots,M-1, M\}$.
%$G = |\mathcal{G}|$ and there is $\mathcal{G} \subseteq \mathcal{S}$.
Being either 1 or 0, $y_i$ denotes whether the $i$-th cluster $C_i$ in $\mathcal{S}$ is chosen or not.
$x_{ij}$ indicates whether the CR node $j$ resides in the cluster $C_i$, \ie $x_{ij}=1$ means node $j$ resides in the cluster $C_i$. 
%Node index $j$ is identical to the node ID.
$N$ is the total number of CR users in network $\mathcal{N}$, $M$ is the number of clusters in $\mathcal{S}$.



The constraints guarantee to obtain the clusters which together include all the CR users and don't overlap.
The first constraint regulates that a CR node should reside in exactly one cluster.
The second constraint regulates that when the $i$-th cluster $C_i$ is chosen, there will be exactly $|C_i|$ CR nodes residing in $C_i$.

%The optimization is a binary linear programming problem.
The objective is to maximize the sum of the numbers of CCs in the clusters which constitute the CRN.
$t_{ij}$ is a constant and there is
%In practice, we can solve the problem with $\mathcal{G} = \mathcal{S}$ when $|\mathcal{S}|$ is not large. 
%
%
%Given a CRN $\mathcal{N}$ and desired cluster size $\delta$, we obtain a collection of clusters $\mathcal{G}$ which contains all the \textit{potential} clusters, and the sizes of these clusters are $1,2,\ldots,\delta$.
%Potential clusters are the clusters which satisfy the conditions introduced in Section~\ref{sec:model}. 
%Note that the potential clusters include the singleton ones.
%By permitting the existence of the singleton clusters, we can ensure that the $\mathcal{S}'$ in Definition~\ref{def_centralized_clustering} is always be feasible.

\begin{equation}
t_{ij} = \frac{q_{ij}}{|C_i|} - p_i(C_i)
\end{equation}
where constant $q_{ij}= |K(C_i)|$ when node $j\in C_i$, and $q_{ij}= 0$ when node $j\notin C_i$.
%$|K(C_i)|$ is the number of CCs of cluster $C_i$, and $|C_i|$ is the size of cluster $C_i$.
$p(C_i)$ is the size-related weight, which is positively related with the difference between $C_i$'s size and the desired size.
Assuming $\delta$ is the desired size, then weight $p$ is decided with respect to cluster sizes 1,2, $\cdots$, $\sigma$ as follows,
$$
p(C_i) = \left\{ \begin{array}{rl}
0 &\mbox{ if $|C_i|=\delta$} \\
\rho_1 &\mbox{if $||C_i|-1|=\delta$} \\
\rho_2 &\mbox{if $||C_i|-2|=\delta$} \\
\vdots\\
\rho_\sigma &\mbox{if $||C_i|-\sigma|=\delta$} \\
\end{array} \right.
$$
where $ 0 < \rho_1< \rho_2 < \cdots < \rho_\sigma$.

%%Based on the knowledge on $\mathcal{S}$, we construct a $M\times N$ matrix $Q_{M\text{x}N}$ which is shown in Figure~\ref{costant_matrix_Q}. 
%%Constant $q_{ij}$ is the element of $Q_{M\text{x}N}$, and its subscripts correspond to the $i$th cluster and CR node $j$ respectively.
%$q_{ij}= |K(C_i)|/|C_i|$ when there is $j\in C_i$, and $q_{ij}= 0$ when there is $j\notin C_i$.
%In other words, each non-zero element $q_{ij}$ means the number of CCs of the cluster $i$ where node $j$ resides.

%\begin{figure}[ht!]
%\centering
%\bordermatrix{~ 		& 1 	& 2 	& 3 	& \cdots & j & \cdots	& N-1 	& N	\cr
%                  1 	& |K(C_1)| 	& |K(C_1)| 	& 0 	& \cdots & \cdots &\cdots	& 0 	& 0	\cr
%                  2 	& |K(C_2)| 	& 0 	& |K(C_2)| 	& \cdots & \cdots & \cdots 	& 0 	& 0	\cr
%				\vdots  	&\vdots & 	 	& 		&  \vdots		& 		& \vdots \cr
%				i 	& 0 	& |K(C_i)| 	& 0 	& \cdots  & \cdots & \cdots 	& |K(C_i)| 	& 0	\cr
%				\vdots  	&\vdots & 	 	& 		&  \vdots & \cdots & \vdots 		& 		& \vdots \cr
%				\vdots 	& 0  	& 0 	& 0 	& \cdots & \cdots & \cdots 	& |K(C_i')| 	& 0	\cr
%				G  	& |K(C_G)| & \cdots	 	& 		&  \vdots	& \cdots & \vdots& 		& \vdots \cr}	
%\caption{An example of Matrix $Q$, its rows correspond to all possible clusters, and columns correspond to the CR nodes in the CRN. }
%\label{costant_matrix_Q}
%\end{figure}

%Now we examine the objective function to see whether it in line with the goal to maximize the total number of CCs meanwhile consider the restriction on the cluster size.
When $t_{ij}$ is replaced by $\frac{q_{ij}}{|C_i|} - p(C_i)$, the objective function becomes,
\begin{equation}
\begin{aligned}
     &\max\limits_{y_i, x_{ij}} && \Sigma_{j=1}^N\Sigma_{i=1}^M (y_i\cdot \frac{q_{ij}}{|C_i|} - y_i\cdot p(C_i)) \\
\notag
\end{aligned}
\label{centralized_opt}
\end{equation}
The sum of the first items is the sum of CCs of all the chosen clusters.
As to the second item, when $w_i$ is 1 ($C_i$ is chosen) and $|C_i|\neq\delta$, it will be negative, which contradicts the direction of the optimization.
Thus the second item discourages the appearance the clusters whose sizes deviate from $\delta$.

The difficulty of using this method lies in obtaining the set $\mathcal{S}$.
In the worst case, \ie every CR node communicates directly with any other node and the CRN forms a full connected graph, the size of $\mathcal{S}$ is $\Sigma_{r=1}^{N}\ {N \choose r} = 2^N-1$.

\section{Distributed Clustering Algorithm: Variants of ROSS}
\label{ross}

In this section we introduce our distributed clustering schemes.
With the variants of ROSS, CR nodes form clusters based on the proximity of the available spectrum in their neighborhood after a series of interactions with their neighbors.
The variants of ROSS consist of two cascaded phases: \textit{cluster formation} and \textit{membership clarification} as shown in Figure~\ref{flowChartROSS}.
\begin{figure}[ht!]
  \centering
\includegraphics[width=0.9\linewidth]{flow_chart.pdf}
	\caption{Processing steps of ROSS}
	\label{flowChartROSS}
\end{figure}

In the first phase, clusters are formed quickly and every CR user becomes either cluster head or cluster member, cluster size control is also implemented	.
In the second phase, non-overlapping clusters are formed in a way that the CCs of relevant clusters are mostly increased.

%is based on the spectrum sensing results in its neighbours , then
	

\subsection{Phase I - Cluster Formation}
\label{phaseI}
Before conducting clustering, we assume spectrum sensing and neighbor discovery are completed, and neighboring nodes exchange their channel availabilities via the dedicated control channel. 
As a result, every CR node is aware of the available channels for themselves and their neighbors.
In this phase, cluster heads are determined after a series of comparisons with their neighbors. 
Two metrics are proposed to characterize the proximity in terms of available spectrum between CR node $i$ and its neighborhood, which will be used to decide on cluster heads.

\begin{itemize}

\item \textit{Individual connectivity degree} $d_i$: $d_i=\sum_{j\in \text{Nb}(i)}\vert K_i\cap K_j\vert$. 
$d_i$ is the total number of the CCs between node $i$ and each of its neighbors.

\item \textit{Neighborhood connectivity degree} $g_i$: the number of CCs which are available for $i$ and all of its neighbors.
$g_i=|\bigcap_{j\in \text{Nb}(i)\cup i}K_j|$, which represents the ability of $i$ to form a robust cluster with its neighbors.
\end{itemize}
Individual connectivity degree $d_i$ and neighborhood connectivity degree $g_i$ together form the \textit{connectivity vector} $(d_i, g_i)$.
Connectivity vector is calculated by every secondary user after channel availability is obtained, and is then broadcasted.
Figure~\ref{fig1} shows a CRN, where dashed edge indicates the end nodes are within each other's transmission range, the number along the dashed line is the number of common channels between the two ends.
The sets of the indices of the available channels sensed by each node are: $K_A=\{1,2,3,4,5,6,10\}, K_B=\{1,2,3,5,7\}, \\K_C=\{1,3,4,10\}, K_D=\{1,2,3,5\}, \\K_E=\{2,3,5,7\}, K_F=\{2,4,5,6,7\}, \\K_G=\{1,2,3,4,8\}, K_H=\{1,2,5,8\}$. 
Each node's connectivity vector is calculated and shown.
\begin{figure}[ht!]
  \centering
\includegraphics[width=0.7\linewidth]{figure1.pdf}
% \includegraphics{figure1.pdf}
	\caption{Connectivity graph of a CRN and the connectivity vector $(d_i, g_i)$ for each node. Primary users are not shown.}
	\label{fig1}
\end{figure}

\subsubsection{Determining Cluster Heads and Forming Clusters}
The procedure of determining cluster heads is as follows.
Each CR node decides whether it is a cluster head by comparing its connectivity vector with neighbors.
When CR node $i$ has lower individual connectivity degree than any of its neighbors except for those which have already been identified as cluster heads, node $i$ becomes a cluster head.
If there is a CR node $j$ in $i$'s neighborhood, and has the same individual connectivity degree as $i$, \ie $d_j = d_i$ and $d_j < d_{k}, \forall k\in \text{Nb}(j)\setminus \{\Lambda\cup i\}$ where $\Lambda$ denotes cluster heads, then out of $i$ and $j$, the node with higher neighborhood connectivity degree will become cluster head.
If $g_i = g_j$ as well, the node ID is used to break the tie, \ie the one with smaller node ID becomes the cluster head.
%
The node which is identified as cluster head broadcasts a message to notify its neighbors of this news, then its neighbors which are not cluster heads become its cluster members.
\footnote{The presence of cluster heads in the neighborhood of a newly formed cluster head will be explained in Section~\ref{ross_p1_guarantee_ccc} and \ref{ross_p2_cluster_pruning})}
During the whole phase I, whenever a CR node becomes cluster head (thus accordingly forms a cluster), or its cluster's composition is changed, the cluster head broadcasts the new information about its cluster, which includes the sets of available channels on itself and all its cluster members.
The pseudo code for the cluster head decision and the initial cluster formation is shown in Algorithm~\ref{alg0} in appendix.

After a CR node, say $i$, receives notification that there is a new cluster head in its neighborhood, $i$ sets its individual connectivity degree to a positive number $M > |\mathcal{K}| \cdot N$, and broadcasts the new individual connectivity degree. 
When node $i$ is associated with multiple clusters, \ie $i$ has received multiple notifications from different cluster heads, $d_i$ is still set to be $M$. 
The manipulation of the individual connectivity degree of the cluster members accelerates the decision on the cluster heads.





\subsubsection{The Existence of Common Channels}
\label{ross_p1_guarantee_ccc}
After executing Algorithm~\ref{alg0}, certain formed clusters may not possess any CCs.
As decreasing cluster size increases CCs within a cluster, for those clusters without CCs, certain nodes need to be excluded to obtain at least one CC.
The sequence of removing is performed according to an ascending list of nodes, which are sorted according to the number of common channels between the nodes and the cluster head. 
In other words, the cluster member which has the least common channels with the cluster head will be removed first.
When there are multiple nodes having the same amount of common channels with the cluster head, the node whose absence brings in more common channels will be removed.
If this criterion meets a tie, the tie can be broken by removing the node with smaller node ID.
It is possible that the cluster head removes all its neighbors before obtaining CCs, which results in a singleton cluster which is composed by itself.
The pseudo code for this procedure is shown in Algorithm~\ref{alg_size_control_available_CCC}.
As for the nodes which are removed from a cluster, they restore their original individual connectivity degrees, then execute Algorithm~\ref{alg0} and become either cluster heads or get included into other clusters afterwards according to Theorem~\ref{clustering:theorem}.




\subsubsection{Cluster Size Control in Dense CRN}
\label{ross_p2_cluster_pruning}

Both analysis and simulation~\cite{2017arXiv170404828L} show that with ROSS, when network density increases to a certain level, the number of formed clusters becomes constant.
This means if the network density keeps on increasing, the cluster size increases linearly with the network density.
Thus It is necessary to control the cluster size when CRN becomes denser, and this task falls upon the cluster heads.

To control the cluster size, cluster heads remove their cluster members when cluster sizes are larger than a threshold.
The threshold should be larger than the desired size $\delta$, because there are overlaps between neighboring clusters.
The desired size $\delta$ is decided based on the capability of the CR users and the tasks to be conveyed.
%Hence, a cluster head excludes some cluster members when the cluster size exceeds a certain threshold.
We set the threshold as $t\cdot \delta$, where the constant parameter $t$ is dependent on the network density and CR nodes' transmission range.
We adopt $t$ to be between 1 and the ratio of the average neighborhood size and desired size.
	When $t$ is smaller, \eg $t=1$, the formed cluster in the phase I will be $\delta$.
	For the cluster whose members are included by other clusters, the size of this cluster will be smaller than $\delta$ after the following membership clarification phase.
	If $t$ is chosen large, \eg $t\cdot\delta$ equals to the size of neighborhood, the mechanism of adjusting the cluster size will not work any more.
	
%Because of $t$, the threshold to prune is larger than the desired size, then there will be some nodes choosing to affiliate with other clusters in the following phases.
%C1-7
The cluster head removes the cluster members sequentially according to the following principle, the absence of one cluster member leads to the maximum increase of CCs in the cluster.
The removed nodes restore their original individual connectivity degrees.
This process ends when each cluster's size is smaller or equal to $t \cdot\delta$.
This procedure is similar with that in Section~\ref{ross_p1_guarantee_ccc}, thus Algorithm~\ref{alg_size_control_available_CCC} can be reused.
%The $t$ is set to 1.3. 	
%C1-7

\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.5\linewidth]{figure2.pdf}
  \caption{Clusters formation after the phase I of ROSS. Nodes $A, B, D$ are debatable nodes as they belong to multiple clusters.}
  \label{fig2}
\end{figure}


%%%%%%%%%%%%%%%
We have the following lemma to show every secondary user will eventually be either integrated into a cluster or becomes a cluster head.

\begin{lemma}
\label{clustering:lemma1}
Given a CRN where any secondary user is able to communicate with any other secondary user through the other nodes, then after the phase of cluster head selection and initial cluster formation, every secondary user either becomes cluster head, or gets included into at least one cluster.
\end{lemma}


The Proof is given in Appendix~\ref{proof_clustering:lemma1}.
%C1-6

\begin{lemma}
\label{clustering:lemma2}
When a secondary user becomes cluster head, it will not become cluster member again.
\end{lemma}
\begin{proof}
A secondary node, say $i$, becomes cluster head when its \textit{individual connectivity degree} is smaller than any of its neighbors.
Afterwards, the \textit{individual connectivity degrees} of its neighbors becomes $M$.
%If all the neighbors stay in the cluster, the cluster head will remain to be cluster head.
If certain nodes are removed from the cluster due to guaranteeing CC or size control, these nodes may become either cluster members of another cluster head, or cluster heads themselves.
In both cases, $i$'s \textit{individual connectivity degrees} is still smaller than these nodes.
Note that when the removed node becomes cluster head, it will not include its former cluster head $i$, so that $i$ doesn't become cluster member and its \textit{individual connectivity degrees} doesn't change.
\end{proof}


\begin{lemma}
\label{clustering:lemma3}
In the process of cluster head selection and initial cluster formation, the maximum number of times that a secondary node becomes cluster head is $N$.
\end{lemma}
This lemma can be easily obtained from~\ref{clustering:lemma2} considering the $N$ is the number of all the secondary users in the CRN.
Based on these Lemmas, we can easily obtain Theorem~\ref{clustering:lemma1},
\begin{theorem}
\label{clustering:theorem}
Assuming the time for a secondary user to update the information about cluster heads in its neighborhood is $T$, then it takes at most $N*T $ to finish the process of cluster head selection and initial cluster formation.
\end{theorem}
Phase I ends when no more secondary users become cluster heads.
Based on Lemma~\ref{clustering:lemma1} and Lemma~\ref{clustering:lemma3}, the theorem is proved.


As Algorithm~\ref{alg0} is executed concurrently by different secondary users, the required time can be considerably reduced.
If we apply Algorithm~\ref{alg0} to the CRN in Figure~\ref{fig1}, the outcome can be found in Figure~\ref{fig2}.
Node $B$ and $H$ have the same individual connectivity degree, i.e., $d_B=d_H$. As $g_H=2>g_B=1$, node $H$ becomes the cluster head and cluster $C(H)$ is $\{H, B, A, G\}$.


\subsection{Phase II - Membership Clarification}
\label{membershipClarification}
%\subsubsection*{Problem Description}
As to the resulted clusters shown in Figure~\ref{fig2} after running phase I of ROSS, we notice that nodes $A, B, D$ are included in more than one cluster. 
We refer to these nodes as \textit{debatable nodes} as their cluster affiliations are not decided.
The clusters which include the debatable node $i$ are called \textit{claiming clusters} of node $i$, and the set of these clusters is denoted as $S_i$.  
The debatable nodes should be exclusively associated with only one cluster and be removed from the other claiming clusters, this procedure is called \textit{cluster membership clarification}.


\subsubsection{Distributed Greedy Algorithm (DGA)}
When a debatable node $i$ decides one cluster $C\in S_i$ to stay and leaves the other its claiming clusters, the principle for $i$ is that its move should result in the greatest increase of CCs in all its claiming clusters.
As node $i$ has been notified of the spectrum availability on all the nodes in each claiming cluster, node $i$ is able to calculate how many more CCs can be produced in a claiming cluster if $i$ leaves that cluster.
Then node $i$ decides on the cluster $C\in S_i$, if $i$ leaving cluster $C$ results in less increased CCs than leaving any other claiming clusters in $S_i$.
%As to a cluster $C\in S_i$, if $i$ leaves cluster $C$ and results in less increased CCs than leaving any other claiming clusters, then $i$ chooses to stay in cluster $C$.
When there comes a tie between two claiming clusters, $i$ chooses to stay in the cluster whose cluster head shares the most CCs with $i$.
When a tie still exists, node $i$ chooses to stay in the claiming cluster which has the smallest size.
Node IDs of cluster heads will be used to break tie in the end if necessary.
The pseudo code of this algorithm is given in Algorithm~\ref{alg4}.
After deciding its membership, debatable node $i$ notifies all its claiming clusters of its choice, and the claiming clusters from which node $i$ leaves also broadcast their new cluster composition and the spectrum availability on all their cluster members.

The autonomous decisions made by the debatable CR nodes raise the concern on the endless chain effect in the membership clarification phase.
A debatable node's choice is dependent on the compositions of its claiming clusters, and the members of these claiming clusters can be changed by other debatable nodes' moves.
As a result, the debatable node which have made decision may not be content with its original move.
There is concern that this process may go on forever.
To erase this concern, we formulate the process of membership clarification into a game, where a equilibrium is reached after a finite number of best response updates made by the debatable nodes.


\subsubsection{Bridging ROSS-DGA with Congestion Game}
\label{clustering:phaseII:game}
Game theory is a powerful mathematical tool for studying, modeling and analyzing the interactions among individuals.
A game consists of three elements: a set of players, a selfish utility for each player, and a feasible strategy space for each player. In a game, the players are rational and intelligent decision makers, which are related with one explicit formalized incentive expression (the utility or cost).
Game theory provides standard procedures to study its equilibriums~\cite{game_for_communication_01}.
In the past few years, game theory has been extensively applied to problems in communication and networking~\cite{Neel06analysisand, Wang_gtc_crn_survey_2010}.
Congestion game is an attractive game model which describes the problem where participants compete for limited resources in a non-cooperative manner, it has the good property that Nash equilibrium can be achieved after finite steps of best response dynamic, \ie each player chooses the strategy to maximize/minimize its utility/cost with respect to the other players' strategies.
The framework of the congestion game has been used to model certain problems in internet-centric applications or cloud computing, where self-interested clients compete for the centralized resources and meanwhile interact with each other.
For example, server selection is involved in distributed computing platforms~\cite{Cloud_Computing_2010}, or users downloading files from cloud, etc.

To formulate the debatable nodes' membership clarification into the desired congestion game, we reexamine this process from a different/opposite perspective. 
From the new perspective, the debatable nodes are not included in any cluster and they need to decide on one cluster to join.
When a debatable node $i$ join one cluster $C$, the decrease of CCs in cluster $C$ is $\sum_{C\in S_i}\Delta\vert K(C) \vert=\sum_{C\in S_i}({\vert K(C) \vert-\vert K(C\cup i) \vert})$.
Then, node $i$ chooses the cluster $C$, where the decrease of CCs in cluster $C$ is smaller than the decrease if $i$ would have joined any other claiming cluster in $S_i$.
The relation between the debatable nodes and the claiming clusters is shown in Figure~\ref{debatable_nodes_claiming_cluster}.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.37\linewidth]{singletongame_matching.pdf}
  \caption{Debatable nodes and claiming clusters}
  \label{debatable_nodes_claiming_cluster}
\end{figure}


In the following, we show that the decision of debatable nodes to clarify their membership can be mapped to the behaviour of the players in a \textit{player-specific singleton congestion game} when proper cost function is given.
The game to be constructed is represented with a 4-tuple $\Gamma=(\mathcal{P},\mathcal{R},\sum_{i, i \in \mathcal{P}}, f)$ with the following elements:

\begin{itemize}
	\item $\mathcal{P}$, the set of players in the game, which are the debatable nodes in our problem.
	\item $\mathcal{R} = \cup S_i, i\in \mathcal{P}$, the set of the resources for players to choose. In our problem, $S_i$ is the set of the claiming clusters of $i$, and $\mathcal{R}$ is the set of all claiming clusters.
	\item Strategy space $\sum_i, i \in \mathcal{P}$, $\sum_i$ is the set of the claiming clusters $S_i$.
	As debatable node $i$ is supposed to choose only one claiming cluster, then only one piece of resource will be allocated to $i$.%, accordingly this congestion game is a singleton game.
	\item 	The cost function $f(C)$ as to a resource $C$. 
	$f(C) = \Delta\vert K^i(C)|, C\in S_i$, which represents the decreased number of CCs in cluster $C$ when debatable node $i$ joins $C$.
	As to cluster $C\in S_i$, the decrease of CCs caused by accepting the debatable nodes is $\sum_{i:C\in S_i, i\rightarrow C} \Delta\vert K^i(C) \vert$. 
$i\rightarrow C$ means $i$ joins cluster $C$.
Obviously this function is non-decreasing with respect to the number of nodes joining cluster $C$.
	
When the utility function is decided purely by the amount of players accessing the resource, the game is a canonical congestion game~\cite{Ackermann06purenash}.
In our game, as the channel availability on debatable nodes (players) is different, the loss of CCs (cost) caused by a debatable node could also be different.
%For example, given two same groups of debatable nodes and their sizes are the same, when the nodes are not completely the same (neither are the channel availabilities on these nodes), the cost happened on one claiming cluster could be different if the two groups of debatable nodes join that cluster respectively.
Hence, this congestion game is player specific~\cite{Ackermann06purenash}.
In this game, every player greedily updates its strategy (choosing one claiming cluster to join) if joining a different claiming cluster minimizes the decrease of CCs $\sum_{i:C\in S_i} \Delta\vert K^i(C) \vert$, and a player's strategy in the game is exactly the same with the behaviour of a debatable node in the membership clarification phase.


%	\item The Rosenthal's potential function \cite{Rosenthal} of this congestion game is given by:
%	\begin{equation*}
%	\phi(S)=\sum_{C\in\mathcal{R}} \sum_{i:C\in S_i} \Delta\vert K^i_C \vert   	
%   	%\sum_{i=1}^N \Delta^{i}_{p}(S)=\sum_{i=1}^N \sum_{r\in S_i}\Delta^{i}_{r}(t)	
%  	% \Delta =\sum_{i=1}^N w_i (x_i - \bar{x})^2 .
%	\end{equation*}
%All the players in this game greedily update their strategy to minimize the potential function (congestion), this process is exactly the same with the network behaviour under \textit{Distributed Greedy Algorithm}. 

%	\item It is an asymmetric game because the sets of strategies shared by different players are different.
%	\item The total cost is: 
%\begin{equation*}
%   \sum_{i=1}^N \Delta^{i}_{p}(S)=\sum_{i=1}^N \sum_{p\in s_i} \Delta^{i}_{p}(n_p(S))
%  % \Delta =\sum_{i=1}^N w_i (x_i - \bar{x})^2 .
%\end{equation*}

%This is the global objective we want to minimize.
\end{itemize}

%Singleton congestion game is a special type of matroid game~\cite{Milchtaich1996111,}. 
%It is known that player-specific matroid congestion game admit pure equilibrium, 

As to singleton congestion game, there exists a pure equilibria which can be reached with the best response update, and the upper bound for the number of steps before convergence is $n^2*m$~\cite{Ackermann06purenash}, where $n$ is the number of players, and $m$ is the number of resources.
In our problem, the players are the debatable nodes, and the resources are the claiming clusters.
Thus the number of steps can be expressed as $\mathcal{O}(N^3)$.
%
In fact, the upper bound for the number of steps which are involved in this process is much smaller than $N^3$.
The percentage of debatable nodes in the network is shown in Figure~\ref{percentage_overlapping_node}, which is between 10\% to 60\%.
On the other hand, the number of clusters heads is dependent on the network density and the CR node's transmission range as mentioned in Section~\ref{phaseI}.
The simulation in \cite{robust_clustering_arxiv} shows the cluster heads account for from 3.4\% to 20\% of the total CR nodes with the increase of network density.
Furthermore, as the game played locally and in parallel \ie a debatable node can only interact with a few claiming clusters, which greatly accelerates the execution speed.


\subsubsection{Distributed Fast Algorithm (DFA)}
On the basis of ROSS-DGA, we propose a faster version ROSS-DFA which differs from ROSS-DGA in the second phase.
With ROSS-DFA, debatable nodes decide their respective cluster heads only once.
The debatable nodes consider their claiming clusters to include all their debatable nodes, thus the membership of claiming clusters is static and all the debatable nodes can make decisions simultaneously without considering the change of membership of their claiming clusters.
As ROSS-DFA is quicker than ROSS-DGA, the former is especially suitable for the CRN where the channel availability changes frequently.
To run ROSS-DFA, debatable nodes execute only one loop in Algorithm~\ref{alg4}.

Now we apply both ROSS-DGA and ROSS-DFA to the network in Figure~\ref{fig2} which has been applied the phase I of ROSS.
%C1-8
In the network, node $A$'s claiming clusters are cluster $C(C), C(H)\in S_A$, their members are $\{A,B,C,D\}$ and $\{A,B,H,G\}$ respectively. 
The two possible strategies of node $A$ is illustrated in Figure \ref{fig3}.
In Figure \ref{AinC}, node $A$ staying in $C(C)$ and leaving $C(H)$ brings 2 more CCs to $S_A$, which is more than that brought by another strategy shown in \ref{AinH}.
After the decisions made similarly by the other debatable nodes $B$ and $D$, the final clusters are formed as shown in Figure~\ref{final_clustering_ross}.

%Using DFA in phase II, the time complexity is decreased drastically to 1. Thus, the total complexity of ROSS-DFA is $|I|$, while, ROSS-DGA's complexity is $|I|^3$ in the worst case.


\begin{figure}[h]
\centering
\subfigure[Node A stays in cluster $C(C)$, quits $C(H)$, $\Delta\vert K(C(C))\vert+\Delta\vert K(C(H))\vert=2$]{
\includegraphics[width=0.435\linewidth]{figure4AinC.pdf}
\label{AinC}
}
\hspace{.15 in}
\subfigure[Node A stays in cluster $C(H)$, quits $C(C)$, $\Delta\vert K(C(C))\vert+\Delta\vert K(C(H))\vert=1$]{
\includegraphics[width=0.435\linewidth]{figure4AinH.pdf}
\label{AinH}
}
\caption[]{Membership clarification: possible cluster formations caused by node A's different choices} %\subref{node A in $C_C$}, \subref{node A in $C_H$}}
\label{fig3}
\end{figure}


\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{final_clustering_ross.pdf}
  \caption{Final formation of clusters. Common channels are shown beside corresponding clusters.}
  \label{final_clustering_ross}
\end{figure}




\section{Performance Evaluation}
\label{performance}
%In this section, we evaluate the performances of ROSS.
The schemes involved in the simulation are as follows,
\begin{itemize}
\item ROSS without size control: ROSS-DGA, ROSS-DFA.
\item ROSS with size control, \ie ROSS-$\delta$-DGA and ROSS-$\delta$-DFA where $\delta$ is the desired cluster size.
In the following, we refer to the above mentioned four schemes as the variants of ROSS.
\item SOC~\cite{LIU_TMC11_2}, a distributed clustering scheme pursuing cluster robustness.
\item Centralized robust clustering scheme. 
As shown in Section~\ref{centralized_solution}, the centralized robust clustering scheme is formulated as an integer linear optimization problem and is solved by MATLAB with the function $bintprog$.
\end{itemize}

%The ROSS without size control mechanism is similar with the schemes proposed in \cite{Li11_ROSS}.



%Before we investigating the performance of the clustering schemes with simulation, we apply the two comparison clustering schemes in the example CRN in Figure~\ref{fig1}, and make an initial comparison in terms of the amount of CCs. 
%As to the centralized robust clustering scheme, we set the desired cluster size $\delta$ as 3, as a result, according to the network topology, the collection of all the possible clusters
%$\mathcal{S}=\{\{A\}, \{B\},\dots,\{B,C\},\{B,A\},\{B,H\},\cdots,\{B,A,C\},$\\$\{B,H,C\}, \{A,D,C\},\cdots\}$, and $|\mathcal{S}|=38$.
%We set $\rho_1$ and $\rho_1$ as 0.2 and 0.8 respectively.
%The formed clusters by the centralized clustering scheme are shown in Fig.~\ref{fig:final_clustering_LP}.
%%$\{\{D,E,F\},\{A,C,G\},\{H,G\}\}$, the numbers of CCs are 2, 3, 3.
%The resulted clustering solutions from SOC is shown in Fig.~\ref{fig:final_clustering_soc}.
%%
%We compare the average number of CCs achieved by different schemes, the results of ROSS\footnote{In this example network, both ROSS-DGA and ROSS-DFA and their size control variants form the same clusters)}, centralized and SOC are 2.66, 2.66, and 3 respectively. 
%Note there is one singleton cluster $C(H)$ generated by SOC, which is not preferred.
%When we only consider the clusters which are not singleton, the average number of CCs of SOC drops to 2.5. 
\begin{figure}[ht]
\begin{center}
\subfigure[Generated by SOC]{\includegraphics[width=0.435\linewidth]{final_clustering_soc}\label{fig:final_clustering_soc}}
\hspace{0.15 in}
\subfigure[Generated by the centralized clustering scheme]{\includegraphics[width=0.435\linewidth]{final_clustering_LP}\label{fig:final_clustering_LP}}
\end{center}
\caption{Final clusters formed by the centralized clustering scheme and SOC.}
\label{fig:final_clustering}
\end{figure}


As to the CRN shown in Figure~\ref{fig1}, the resulting clusters by the centralized scheme and SOC are shown in Figure~\ref{fig:final_clustering}.
We now investigate the performances of the schemes in the following aspects.

\begin{itemize}
\item \textbf{The average number of CCs per non-singleton cluster.}
Non-singleton cluster refers to the cluster whose cluster size is larger than one.
Previous work \cite{LIU_TMC11_2} and \cite{Li11_ROSS} claim that the larger average number of CCs over all the clusters indicates robustness , from which we see two flaws.
First, the unclustered CR nodes (synonym of singleton clusters) should not be considered when calculating the average number of CCs, as singleton clusters don't contribute to the collaborative computing or sensing.
Second, the average number of CCs doesn't necessarily indicate the robustness of individual clusters, because the ability for a cluster to sustain also depends on cluster size and the locations of the cluster members, but these information can not be illustrated in the average number of CCs.
In the performance evaluation, we will examine the metric of average number of CCs per non-singleton cluster, which excludes the bias brought in by the unclustered CR nodes.
Moreover, we will examine whether this metric reflects the robustness of the clusters.


\item \textbf{Robustness of the clusters against newly added PUs.}
Robustness is illustrated by the number of the unclustered CR nodes in the CRN, after the CRN being challenged by the increasing number of PUs.
This metric indicates the robustness of the clusters, \ie as to the clusters formed for a given CRN and spectrum availability, how many CR nodes can still be benefited from the clusters when the spectrum availability decreases.

\item \textbf{Cluster sizes.}
%Specific clusters size is pursued in many applications due to energy preservation and the system design ~\cite{clustering_globecom11}.
We investigate the distribution of CRs residing in the formed clusters with different sizes.



\item \textbf{Amount of control messages involved.}
We investigate the number of control messages involved in the clustering process.

\item \textbf{Influence from inaccurate spectrum sensing.}
The above simulations are conducted under the assumption of perfect spectrum sensing.
As spectrum sensing in practise is subject to errors, we are interested to see the performance of the distributed schemes when the spectrum sensing is not perfect.
%The errors in spectrum sensing is inevitable, and the decision is made by the secondary users and based on the sensing results, without considering the difference between the sensing result and the ground truth.
The false negative in spectrum sensing, which misdetects the presence of the active primary users, is harmful to the primary users and should be avoided as much as possible.
On the contrary, a false positive \ie which reports the presence of active primary users when there are actually none, only decreases the available spectrum for the secondary users.
In this regard, we assume only the false negative exists in the spectrum sensing.

We assume when a secondary user is within the transmission range of an active primary user, the probability that it misdetects and thus regards a channel as being available equals to the rate of false negative.
The secondary users make clustering decisions based on the imperfect spectrum sensing.
After the clustering process is completed, we correct the spectrum availability with the ground truth.
Then certain formed clusters may be affected as their CCs which are obtained due to false negative will be revoked.
%When the clustering process is completed, we will examine the performances on robustness and cluster size control with the group truth spectrum availability.
%C3
\end{itemize}


The simulation consists of two parts, first we investigate the performance of centralized scheme and the distributed schemes in a small network, as there is no polynomial time solution available to solve the centralized problem.
In the second part, we investigate the performance of the proposed distributed schemes in the CRN with different scales and densities.
The following simulation setting is the same for both simulation parts.
CRs and PUs are deployed on a two-dimensional Euclidean plane.
%Complying with the system model, the CR node residing within another CR node's transmission range is seen as neighbour of that CR node.
The number of licensed channels is 10, each PU is operating on each channel with probability of 50\%.
The other parameters \ie the number of CR and PU, and their transmission ranges are given in the beginning of the respective simulation sections.
%C1-10
The constant $t$ which is used to control cluster size for ROSS (discussed in Section~\ref{ross_p2_cluster_pruning}) is 1.3.
CR users are assumed to be able to sense the existence of primary users and identify available channels.
All primary and CR users are assumed to be static during the process of clustering.
The simulation is written in C++, and the performance results are averaged over 50 randomly generated topologies, and the confidence interval corresponds to 95\% confidence level.


\subsection{Centralized Schemes vs. Decentralized Schemes}
In this part of simulation, there are 10 primary users and 20 CR users dropped randomly (with uniform distribution) in a square area where side length is $A$.
$A$ is a positive value and the transmission ranges of both primary and CR users are set to $A/3$.
By doing this, we try to abstract from the influence of any given physical layer technology, and A can be given a concrete value in practice when the physical layer technology is decided.
%C1-10, C1-9
%There are 10 available channels. 
%With this setting, the average number of neighbours of one CR user is 4.8.
%Each primary user randomly occupies one channel, and 
When clustering scheme is executed, around 7 channels are available on each CR node.
The desired cluster size $\delta$ is 3.
As for the centralized scheme, the parameters used in the \textit{punishment} for choosing the clusters with undesired sizes are set as follows, $\rho_1 =  0.4$, $\rho_2 =  0.6$.


\subsubsection{CCs in Non-singleton Clusters}
\label{ccc_20}
Figure~\ref{ccc_per_nonsingleton} shows the centralized schemes outperform the distributed schemes.
SOC achieves the most CCs among the distributed schemes, because SOC groups the neighboring CRs which share the most abundant spectrum together, without considering the number of them.
%We have discussed the flaw of this metric as it doesn't convey the number of unclustered CR nodes, in fact, 
As a result, SOC also generates the most unclustered CRs.
As to the variants of ROSS, we notice that the greedy mechanism increases CCs in non-singleton clusters significantly.
%, this is due to the procedure that debatable nodes greedily look for better affiliation to improve the number of CCs.
%We also notice that the size control feature doesn't affect the number of CCs for both ROSS-DGA and ROSS-DFA.
%Size control mechanism converts the large clusters into small ones, but meanwhile clusters with the desired sizes have to be made when forming smaller clusters is possible.
%, which can also be observed in the large scale CRN in Section~\ref{largeScaleCRN}.

\begin{figure*}[th]
\begin{multicols}{3}
    \includegraphics[width=\linewidth]{ccc_20.pdf}\par\caption{Average number of CCs of non-singleton clusters}\label{ccc_per_nonsingleton}
    \includegraphics[width=\linewidth]{cdf_clusterSize_20.pdf}\par\caption{Cumulative distribution of CRs residing in clusters with different sizes}\label{size_control}    
    \includegraphics[width=\linewidth]{survival_rate_20.pdf}\par\caption{Number of unclustered CRs with decreasing spectrum availability}\label{singleton_clusters}
\end{multicols}
\label{compare_dis_centralized}
\end{figure*}



\subsubsection{Cluster Size}
\label{cluster_size}


Figure~\ref{size_control} depicts the empirical cumulative distribution of the CRs in clusters of different sizes.
%First, given the channel availability in the CRN, SOC generates more unclustered CR nodes than other schemes.
The centralized schemes don't produce unclustered CR nodes in the simulation.
The unclustered nodes generated by ROSS-DGA/DFA account for 3\% of the total CR nodes, as comparison, 10\% of nodes are unclustered when applying SOC.
ROSS-DGA and ROSS-DFA with size control feature generate 5\%-8\% unclustered CR nodes, which is due to the cluster pruning procedure (discussed in Section~\ref{ross_p1_guarantee_ccc} and Section~\ref{ross_p2_cluster_pruning}).

In terms of cluster size, the clusters resulted from centralized schemes and ROSS with cluster size control mechanism have little deviation from the desired cluster size.
%As to ROSS-DFG and ROSS-DFA with size control feature, CR nodes reside averagely in clusters whose sizes are 2, 3 and 4.
The sizes of clusters resulted from ROSS-DGA and ROSS-DFA are disperse, but appear to be better than SOC, i.e., the 50\% percentiles for ROSS-DGA, ROSS-DFA and SOC are 4.5, 5, and 5.5, and the 90\% percentiles for the three schemes are 8, 8, and 9, the corresponding sizes resulted by ROSS are closer to the desired size.



\subsubsection{Robustness of the formed clusters}
%When the number of PUs in CRN increases, or their operation becomes more intensive, some clusters don't seize any CCs any more, so that the cluster members and the cluster heads become unclustered, or singleton clusters.
%If there is no common channels available any more because of the new added PUs, the cluster is regarded as destroyed and the former cluster member CRs become unclustered CRs or in other words singleton clusters.
%We investigate the number of singleton clusters with primary users whose intensity of activities are varying.
%We will obtain two observations by examining this metric.
%First, we will know how many CR nodes are unclusterred by applying the robust clustering schemes in a given CRN.
In this part of simulation, we put PUs sequentially into CRN to decrease the available spectrum.
10 PUs are in the network at start, extra 19 batches of PUs are added sequentially and each batch includes 5 PUs. 
Figure~\ref{singleton_clusters} shows certain clusters can not maintain and the number of unclustered CR nodes increases when the number of PUs increases.
The centralized scheme with desired size of 2 generates the most robust clusters, meanwhile, SOC results in the most vulnerable clusters.
The centralized scheme with desired size of 3 doesn't outperform the variants of ROSS, because pursuing cluster size prevents forming the the clusters with more CCs.
In contrary, the variants of ROSS generate some smaller clusters which are more likely to maintain when there are more PUs.

Considering the number of secondary users residing in a cluster, ROSS based schemes benefit 5\%, 30\% and 230\% more secondary users from neighborhood cooperation than SOC, when the numbers of newly added PR are 10, 40 and 80 respectively.
The above observation also shows the average number of CCs of non-singleton clusters doesn't necessarily illustrate the robustness  of cluster, \ie SOC obtains the most CCs among the distributed schemes, but the resulted clusters are vulnerable.


\subsubsection{Control Signaling Overhead}

In this section we compare the overhead of signaling involved in different clustering schemes.
We count the number of \textit{transmissions of control messages} as message complexity~\cite{complexity_aggregation_2011}, without distinguishing broadcast or uni-cast control messages.
In Section~\ref{ross}, this metric is synonymous with the \textit{the number of updates}.
%We don't consider the the control messages which are involved in neighborhood discovery, which is the premise and deemed to be the same for all clustering schemes.
%According to~\cite{complexity_aggregation_2011}, the message complexity is defined as the number of messages used by all nodes.

As to ROSS, in the first phase the maximal number of broadcast is $N$ according to~\ref{clustering:theorem}.
The upper bounds for the transmissions are $n^2m$ and $n$ for ROSS-DGA and ROSS-DFA respectively.
Scheme SOC consists of three rounds, and in each round every node needs to broadcast to do comparisons and cluster mergers.
The centralized scheme is conducted at the centralized control device, which involves information aggregation and clustering decision dissemination.
To analyze the centralized scheme's message complexity, we adopt the backbone structure proposed in~\cite{Efficient_broadcasting_gathering_adhoc}, and apply ROSS to generate cluster heads which serve as the backbone.
In the process of information aggregation, all the nodes transmit information to the cluster heads which forward the messages to the controller. 
In the process of dissemination, all the cluster heads and the debatable nodes broadcast the clustering result, thus the upper bound for the number of broadcast is $N+m+n$.

%, when a CR node decides itself to be the cluster head, it broadcasts a message containing its ID, cluster members and the set of CCs in its cluster.
%In the second phase, a debatable node broadcasts its affiliation to inform its claiming clusters, then the cluster heads of the claiming clusters broadcast message about the new cluster members if they are changed due to the debatable node's decision.
%The upper bound of the total number of the control messages involved in cluster formation is analyzed in Theorem~\ref{clustering:theorem} and Section~\ref{clustering:phaseII:game}.
%
%The comparison scheme SOC consists of three rounds of execution. 
%In the first two rounds, every CR node maintains its own cluster and seeks either to integrate neighboring clusters or to join one neighboring cluster.
%The final clusters are obtained in the third round. 
%In each round, every CR node is involved in comparisons and cluster mergers.
%%Comparing with the second phase of ROSS, only debatable nodes to communicate with cluster heads to clarify their membership.
%%The signalling overhead for centralized scheme comes from two processes, the the process of collecting information to the centralized controller, and the process that the controller spreads the clustering result to all the CR nodes.
%
%The centralized scheme is conducted at the centralized control device, but it involves two phases of control message transmission.
%The first phase is information aggregation, in which every CR node's channel availability and neighborhood is transmitted to the centralized controller.
%iIn the second phase, the control broadcasts the clustering solution, which is disseminated to every CR node.
%%
%We adopt the algorithm proposed in~\cite{Efficient_broadcasting_gathering_adhoc} to broadcast and gather information as the algorithm is simple and self-stabilizing.
%This scheme needs building a backbone structure to support the communication. 
%We apply ROSS to generate cluster heads which serve as the backbone, and the debatable nodes are used as the gateway nodes between the backbone nodes.
%As the backbone is built for one time and supports the transmission of control messages later on, we don't take account the messages involved in building the backbone.
%As to the process of information gathering, we assume that every cluster member sends the spectrum availability and its ID to its cluster head, which further forwards the message to the controller, then the number of transmissions is $N$.
%As to the process of dissemination, in an extreme situation where all the gateway and the backbone nodes broadcast, the number of transmissions is $m + n$, where $m$ is the number of cluster heads and $n$ is number of debatable nodes.

The number of control messages which are involved in ROSS variants and the centralized scheme is related with the number of debatable nodes.
Figure~\ref{percentage_overlapping_node} shows the percentage of debatable nodes with different network densities.
\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.6\linewidth]{percentage_overlapping_node.pdf}
  \caption{The percentage of debatable nodes after phase I of ROSS.}\label{percentage_overlapping_node}
\end{figure}
%
%As we adopt a simplified communication model, node's transmission is not influenced by collision or interference, 
%Our simulation doesn't consider the behaviour in the physical layer, 
%
%
%Assume we use OSPF~\cite{BCJ10} to aggregate and disseminate information, then the best and worst complexity for is $\mathcal{O}(E)$, where $E$ is the number of edges in the graph which corresponds to the network.
%The minimum number of edges is $n-1$ when the nodes form a line and each node has at more two neighbours, and the maximum number is $N*(N-1)/2$ when the nodes form a complete graph.
%Thus the best message complexity of the centralized scheme is $\mathcal{O}{(N)}$ and the worst is $\mathcal{O}{(N^2)}$.
%
%1. update membership to form X1, 
%2. broadcast new X1, form new X2
%3. broadcast X3
%The complexity parameters are the number of nodes $n$ in network, number of clusters $h$.
Table \ref{tab_overhead} shows message complexity, quantitative amount of control messages, and size of control messages.
Figure~\ref{control_msg} shows the analytical result of the amount of transmissions involved in different schemes.
%the upper bound of the number of transmissions of ROSS, and the analytic number of transmissions of the centralized scheme. 

\begin{center}
\begin{table*}[!htb]
\caption{Signalling overhead}\label{tab_overhead}
{\renewcommand{\arraystretch}{1.15} %<- modify value to suit your needs
{\small
\hfill{}
\begin{threeparttable}
\begin{tabular}{|C{1.8 cm}|C{2.6 cm}|C{3 cm}|C{6.3 cm}|}
\hline
 Scheme 				&Message Complexity 	&   Quantitative number of messages 		& Content and size of the message 									\\ \hline
 ROSS-DGA, ROSS-$\delta$-DGA 	&$\mathcal{O}(N^3)$ (worst case)		&   $N+n^2m$ (upper bound)  				&   \multirow{2}{*}{\parbox{7.7cm}{PhaseI: ID, $d_i$,$g_i$, which are 3 bytes;\\ PhaseII: Cluster head $i$ broadcasts channel availability to all \\ members, where are $|C(i)| |\mathcal{K}|$ bytes}}								\\ \cline{1-3}
 ROSS-DFA, ROSS-$\delta$-DFA 	&$\mathcal{O}(N)$ (worst case)		&   $N + n$	 (upper bound) 					& 	      												\\ \hline
 SOC 					&$\mathcal{O}(N)$		&   $3N$									& Every CR node $i$ broadcasts channel availability on all cluster members, which is $|C(i)| |\mathcal{K}|$ bytes
 \\ \hline
 Centralized			&$\mathcal{O}(N)$			&	$N + n + m$ (upper bound) 		& clustering result, which is 2$N$ bytes \tnotex{tnote:robots-r1} 					\\ \hline
\end{tabular}
    \begin{tablenotes}
      \item\label{tnote:robots-r1}Assuming the data structure of the clustering result is in the form of $\{i, C\}, i\in C, i\in \mathcal{N}$.
    \end{tablenotes}
    \end{threeparttable}
}
}
\hfill{}
\end{table*}
\end{center}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.6\linewidth]{number_controlMsg.pdf}
  \caption{Quantitative amount of control messages.}
  \label{control_msg}
\end{figure}





\subsection{Comparison among the Distributed Schemes}
\label{largeScaleCRN}
In this section we investigate the performances of the proposed distributed clustering schemes with different network scales and densities.
The transmission range of CR is $A/5$, PU's transmission range is $2A/5$.
The initial number of PU is 30.
%The number of CR is 100, 200 and 300, and the average number of neighbours of each CR is 9.5, 20, and 31.
The desired sizes adopted are listed in the Table~\ref{Simulation_para}, which is about 60\% of the average number of neighbors.
%When run ROSS, the parameter $t$ which is used to control cluster size in phase I is 1.3.


\begin{table}[ht]
\caption{}
\label{Simulation_para}
{\small
%\hfill{}
\begin{tabular}{|L{3 cm}|C{0.85 cm}|C{0.85 cm}|C{0.85 cm}|}
\hline
Number of CRs			& 100 	&  200 					& 300 \\ \hline
Average num. of neighbors 	&9.5	&   20		& 31  \\ \hline
Desired size $\delta$ 	& 6	&   12 						& 20      \\ \hline
\end{tabular}
}
%\hfill{}
\end{table}



\subsubsection{Number of CCs per Non-singleton Clusters}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=.7\linewidth]{ccc_large_scale_color_082017_newdata_no_texture.pdf}
  \caption{Average number of CCs of non-singleton clusters}
  \label{ccc_large_scale}
\end{figure}

The average number of CCs of the non-singleton clusters is shown in Figure~\ref{ccc_large_scale}.
Here we don't see the obvious difference between different schemes on the number of CCs.
%SOC achieves the most CCs per non-singleton cluster, but the lead over the variants of ROSS decreases significantly when $N$ increases.
%This means SOC out performs in terms of the average number of CCs per non-singleton cluster when network is sparse.
%This is also observed in the evaluation in Section \ref{ccc_20} where $N=20$.
%When the network becomes denser, even this metric favours SOC as discussed in the beginning of Section~\ref{performance}, ROSS-DGA achieves even more CCs than SOC, and ROSS-DFA and ROSS-$\delta$-DGA increase the number of CCs visibly.




\subsubsection{Robustness of the Formed Clusters}
Here we see how robust clusters are when exposed to the increasing influence of PUs.
We increase primary users' activity by importing 20 batches of PUs sequentially in CRN, where each batch includes 10 PUs. 
%
Figure~\ref{singleton_clusters_100} and \ref{singleton_clusters_200} show when $N=100$ and 200, with the same intensity of PUs' activities, more unclustered CR nodes are resulted from SOC than the variants of ROSS,  
When $N=300$ as shown in Figure~\ref{singleton_clusters_300} and new PUs are not many, ROSS-DGA/DFA generate slightly more unclustered CR nodes than SOC, but SOC's performance deteriorates quickly when the number of PUs continue increasing.
%
From Figure~\ref{singleton_clusters_100} to~\ref{singleton_clusters_300}, we can see that significantly less unclustered CR nodes are generated by ROSS with size control mechanism.
Besides, the greedy mechanism moderately strengthens the robustness of the clusters.
%We only show the average values of the variants of ROSS as their confidence intervals overlap.




\begin{figure*}[t]
\begin{multicols}{3}
    \includegraphics[width=\linewidth]{survival_rate_100_edge50.pdf}\par\caption{100 CRs}\label{singleton_clusters_100}
    \includegraphics[width=\linewidth]{survival_rate_200_edge50.pdf}\par\caption{200 CRs}\label{singleton_clusters_200}
    \includegraphics[width=\linewidth]{survival_rate_300_edge50.pdf}\par\caption{300 CRs}\label{singleton_clusters_300}
\end{multicols}
%\caption{Percentage of CR nodes which are not included in any non-singleton clusters}
%\label{unclustered_100_200_300}
\end{figure*}

%When the network is denser, the improvement on cluster sizes and robustness by the greedy search in the membership clarification phase is more obvious.

\begin{figure*}[t]
\begin{multicols}{3}
    \includegraphics[width=\linewidth]{cdf_clusterSize_100.pdf}\par\caption{100 CRs, 30 PUs in network}\label{cdf_clusterSize_100}
    \includegraphics[width=\linewidth]{cdf_clusterSize_200.pdf}\par\caption{200 CRs, 30 PUs in network}\label{cdf_clusterSize_200}
    \includegraphics[width=\linewidth]{cdf_clusterSize_300.pdf}\par\caption{300 CRs, 30 PUs in network}\label{cdf_clusterSize_300}
\end{multicols}
%\caption{Cumulative distribution of CRs residing in clusters with different sizes}
%\label{cdf_100_200_300}
\end{figure*}

\subsubsection{Cluster Size Control}
Figure~\ref{nClusters_largeNetwork} shows when network density increases, \ie $N$ changes from 100 to 300 in the same area, the number of clusters resulted from SOC increases linearly, whereas that by ROSS increases by a smaller margin.
This result coincides with the analysis in Section~\ref{ross_p2_cluster_pruning}.
%When the network becomes denser, more clusters are generated by SOC compared with ROSS variants.
To see the distribution of the sizes of formed clusters, for each network density, we depict empirical cumulative distribution of CR nodes which are in clusters with different sizes in Figures~\ref{cdf_clusterSize_100}~\ref{cdf_clusterSize_200}~\ref{cdf_clusterSize_300} respectively.
\begin{figure}[!h]
  \centering
   \includegraphics[width=0.7\linewidth]{nClusters_largeNetwork_no_texture.pdf}
  \caption{The number of formed clusters.}
  %, there are $x=6$ when $N=100$, $x=12$ when $N=200$, $x=21$ when $N=300$, which is around $2/3$ of the number of average neighbours.
  \label{nClusters_largeNetwork}
\end{figure}

The cluster sizes resulted from the variants of ROSS are in proximity to the desired size, \ie as shown in Figures~\ref{cdf_clusterSize_100}, 90\% of CR nodes are in the clusters whose sizes are between 3 and 9, while for SOC, only 17\% of nodes are in the clusters with these sizes.
Similarly, when $N=200$ and desired size is 12 as shown in Figure~\ref{cdf_clusterSize_200}, 80\% of nodes are in the clusters whose sizes are between 6 and 18, meanwhile only 30\% of nodes are in the clusters with these sizes when SOC is executed.
%Now we check how many CR nodes are in the clusters whose sizes deviate not much from the desired size, where we put the deviation limit at $\pm 50\%$ of the desired size.
The clusters sizes from ROSS-$\delta$-DGA and ROSS-$\delta$-DFA concentrates more around the desired size than that from ROSS-DGA and ROSS-DFA.
In contrary, the clusters from SOC demonstrates obvious divergence on cluster sizes.

%This means that the sizes of the clusters generated by ROSS-DGA are limited by the network density, and the size control feature further restricts the appearances of the big clusters, thus when the variants of ROSS are implemented, most of the CR nodes are in the clusters which are slightly smaller than the desired size. 
The limitation of distributed scheme ROSS is it doesn't generate clusters whose sizes exceed the cluster head's neighborhood.
The reason is with ROSS, cluster heads form clusters on the basis of their neighborhood, thus don't involve the nodes out of the neighborhood.

\subsubsection{The Performance with False Negative in Spectrum Sensing}


Figure~\ref{false_negative_ccc} shows the average number of CCs decrease slightly when the false negative rate increases.
The size distribution of the ROSS-DGA, ROSS-$\delta$-DGA and SOC is shown in Figure~\ref{false_negative_CDF}.
\begin{figure}[!h]
  \centering
   \includegraphics[width=0.7\linewidth]{false_negative.pdf}
  \caption{The number of CCs per non-singleton cluster with the presence of spectrum sensing false negative}
  \label{false_negative_ccc}
\end{figure}
For all the schemes, when false negatives increase, the number of singleton clusters and smaller clusters increases accordingly.
The clusters resulted from SOC are affected by the sensing errors heavily.
More unclustered nodes are generated, and a lot of small clusters are formed, \eg when false negative rate is 30\%.
In contrary, ROSS variants are resilient in terms of unclusterd nodes and cluster sizes.
We can conclude that due to the negotiation within neighborhoods, ROSS variants successfully rules out the channels obtained due to false negative sensing.
\begin{figure}[!h]
  \centering
   \includegraphics[width=0.7\linewidth]{draw_cdf_clusterSize_with_false_negative.pdf}
  \caption{100 CRs with false negative in spectrum sensing, 30 PUs in network}
  \label{false_negative_CDF}
\end{figure}

\subsection{Insights Obtained from the Simulation}
The simulation with large CRN network confirms the conclusion drawn from the small CRN network.
First, the average number of CCs per cluster, which is adopted as metric for cluster robustness, is not able to tell the robustness against the increasing influence of the primary users.
Second, the centralized clustering scheme forms the clusters which satisfy the requirement on cluster size, and the resulted clusters are robust against PUs' increasing activity, besides, it involves the smallest control overhead in the process of clustering.
Third, as distributed schemes, the variants of ROSS outperform SOC considerably in the following four aspects.
\begin{itemize}[noitemsep,topsep=0pt]
\item The variants of ROSS generate less unclustered nodes than SOC for a given CRN, and the resulted clusters are more robust than SOC when PUs become more active.
\item The amount of signaling overhead involved in ROSS is about half of that needed for SOC, and the signaling messages are much shorter that the latter.
\item Compared with SOC, the clusters generated by ROSS don't appear with a wide span of sizes. ROSS with size control mechanism result in the clusters whose sizes are in proximity to the desired size.
\item The variants of ROSS are more resilient against the erroneous spectrum sensing.
\end{itemize}

Moreover, the ROSS variants with size control features achieve similar performance to the centralized scheme in terms of cluster size, and the cluster robustness is similar when applying the variants of ROSS and the centralized scheme respectively.
%
Among the variants of ROSS, the greedy mechanism in ROSS-DGA helps to improve the performance on cluster size and cluster robustness at the cost of increased signaling overhead.
%We also notice that as a metric, the number of CCs per non-singleton cluster doesn't indicate the robustness of clusters as shown in Figure~\ref{singleton_clusters} and \ref{unclustered_100_200_300}, although it is adopted as the metric in the formation of clusters.

\section{Conclusion}
\label{conclusion}
In this paper we investigate robust clustering problem in CRN thoroughly and propose both centralized and distributed clustering solutions.
We give mathematical description of the problem and prove NP hardness of it.
The proposed centralized scheme generate clusters which have long life expectancy against primary users, and the cluster sizes are close to the desired cluster size.
%The distributed scheme not only results in more robust clusters, but the cluster sizes are in a smaller range than the comparison scheme.
%The congestion game model in game theory is used to design the distributed schemes.
%A Light weighted clustering scheme ROSS is also proposed.
Through simulation, the distributed schemes demonstrate similar performance with the centralized scheme in terms of cluster robustness, signaling overhead and cluster sizes.
The distributed scheme outperforms the comparison distributed scheme by generating more robust clusters,  generating clusters whose sizes are in a smaller range, and being more resilient against the erroneous spectrum sensing.

% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%

\vspace{50mm} %xx mm vertical space

\appendices
\section{Peudo Code for Algorithm~\ref{alg0}, \ref{alg_size_control_available_CCC}, \ref{alg4}}
\begin{algorithm}              % enter the algorithm environment
\caption{ROSS phase I: cluster head determination and initial cluster formation for CR node $i$}          % give the algorithm a caption
\label{alg0} 
\DontPrintSemicolon
\SetAlgoLined
\KwIn{$d_j, g_j, j\in \text{Nb}(i)\setminus \Lambda$, $\Lambda$ denotes the set of cluster heads among $\text{Nb}(i)$. Empty sets $\tau_1,\tau_2$}
\KwResult{Returning 1 means $i$ is cluster head, and $d_j$ is set to 0, $j\in \text{Nb}(i)\setminus \Lambda$. Returning 0 means $i$ is not cluster head.}
%C1-6-wording
\If{$\nexists j\in \text{Nb}(i)\setminus \Lambda$, such that $d_i \geq d_j$}{
	return 1;
	}
\eIf{$\exists j\in \text{Nb}(i)\setminus \Lambda$, such that $d_i > d_j$}{
	return 0;}{
	\If{$\nexists j\in \text{Nb}(i)\setminus \Lambda$, such that $d_j == d_i$}{
	$\tau_1 \leftarrow j$
	}
}
\If{$\nexists j\in \tau_1$, such that $g_i \leq g_j$}{
	return 1;
	}
\eIf{$\exists j\in \tau_1$, such that $g_i < g_j$}{
	return 0;
	}
	{\If{$\nexists j\in \tau_1$, such that $g_j == g_i$}{
		$\tau_2\leftarrow j$
		}
	}
\If{$\texttt{ID}_i$ is smaller than any $\texttt{ID}_j$, $j\in \tau_2\setminus i$}{
	return 1;
	}
	{return 0;
	}
\end{algorithm}


\begin{algorithm}               % enter the algorithm environment
\caption{ROSS phase I: cluster head guarantees the availability of CC (start from line 1) / cluster size control (start from line 2)}          % give the algorithm a caption
\label{alg_size_control_available_CCC}
\DontPrintSemicolon
\SetAlgoLined
\KwIn{Cluster C, empty sets $\tau_1, \tau_2$}
\KwOut{Cluster C has at least one CC, or satisfies the requirement on cluster size}
%\tcc*[r]{When to guarantee available CCs, execute from line 1, when to control cluster size, execute from line 2}
\While {$K_C =\emptyset$} {
\While{$|C|> t\cdot \delta$}{
	%calculate $\lambda = \min_{i\in C, i\neq H_C}(|K_{H_C}\cap K_i|)$;\\
	\eIf{$\exists$ only one $i\in C\setminus h(C)$, $i = \argmin(|K_{h(C)}\cap K_i|)$}{
			$C=C\setminus i$;
		}{
				$\exists$ multiple $i$ which satisfies $i = \argmin(|K_{h(C)}\cap K_i|)$;\\ $\tau_1\leftarrow i$;		
		}
		
	\eIf{$\exists$ only one $i\in \tau_1$, $i = \argmax(|\cap_{j\in C\setminus i} K_j|-|\cap_{j\in C} K_j|)$}{
		$C=C\setminus i$;
		}{
			%$\exists$ multiple $i$ which satisfies $i = \argmax(|\cap_{j\in C\setminus i} K_j|-|\cap_{j\in C} K_j|)$;\\
			$C=C\setminus i$, where $i = \argmin_{i\in \tau_1} \texttt{ID}_i $
			%$\texttt{ID}_i$ is smaller than any $\texttt{ID}_j$, $j\in \tau_2\setminus i$;
		}
	}
}
\end{algorithm}


%\section{}
\begin{algorithm}               % enter the algorithm environment
\caption{Debatable node $i$ decides its affiliation in phase II of ROSS}
%, chooses one claiming cluster to stay and leaves all the other claiming clusters}          % give the algorithm a caption,  cluster to settle
\label{alg4}
\DontPrintSemicolon
\SetAlgoLined
\KwIn{all claiming clusters $C\in S_i$}
\KwOut{one cluster $C\in S_i$, node $i$ notifies all its claiming clusters in $S_i$ about its affiliation decision.
}
\While{$i$ has not chosen the cluster, or $i$ has joined cluster $\tilde{C}$, but $\exists C'\in S_i, C'\neq \tilde{C}$, which has $|K(C'\setminus i)|-|K(C')|<|K(C\setminus i)|-|K(C)|$}{
	\eIf{$\exists$ only one $C\in S_i$, $C = \argmin(|K(C\setminus i)| - |K(C)|)$}{
			return $C$;
		}{
				$\exists$ multiple $C\in S_i$ which satisfies $C = \argmin(|K(C\setminus i)| - |K(C)|)$;\\ 
				$\tau_1\leftarrow C$;		
		}
	\eIf{$\exists$ only one $C\in \tau_1$, $C = \argmax(K_{h(C)}\cap K_i)$}{
			return $C$;
		}{
				$\exists$ multiple $C\in S_i$ which satisfies $C = \argmax(K_{h(C)}\cap K_i)$;\\ 
				$\tau_2\leftarrow C$;		
		}
	\eIf{$\exists$ only one $C\in \tau_2$, $C = \argmin|C|)$}{
			return $C$;
		}{
				return $\argmin_{C\in \tau_2}h(C)$;\\
		}
		}
\end{algorithm}


\section{Proof of Lemma~\ref{clustering:theorem}}
\begin{proof}
\label{proof_clustering:lemma1}
We consider a CRN which can be represented as a connected graph.
% (COMMENT: Why is it necessarily connected? No special case where the graph has two components? ANSWER(Di): It is possible for the graph to have two components. My point it, when theorem works in one component, it works in the complete graph.)
To simplify the discussion, we assume the secondary users have unique individual connectivity degrees. 
Each user has an identical ID and a neighborhood connectivity degree.
This assumption is fair as the neighborhood connectivity degrees and node ID are used to break ties in Algorithm~\ref{alg0}, when the individual connectivity degrees are unique, it is not necessary to use the former two metrics. 
%(COMMENT: What do you mean by breaking ties?? I don't see why your argument holds. ANSWER(DI): according to Algorithm 1, to decide whether node $i$ is a cluster head, the comparision on $i$'s certain degrees with its neighbors needs to be made. It is possible that $i$ has the same degree with some neighbors, then we need ID to decide whether $i$ is cluster head.)

%we assume every node has at least one neighbour.
For the sake of contradiction, let us assume there exist a secondary user $\alpha$ which is not included into any cluster.
Then there exists a node $\beta\in \text{Nb}(\alpha)$ such that $d_{\alpha} > d_{\beta}$ (otherwise $\alpha$ becomes cluster head). 
In this case, according to Algorithm~\ref{alg0}, $\beta$ is not included in any clusters, because otherwise $d_{\beta} = M$, a large positive integer, which contradicts to $d_{\alpha} > d_{\beta}$.
Now, we distinguish between two cases: 
%Otherwise, node $\alpha$ is eligible to form a cluster. COMMENT: unnecessary sentence!
If $\beta$ becomes cluster head, node $\alpha$ is included, the assumption is not true.
If $\beta$ is not a cluster head, then $\beta$ is not in any cluster, we can repeat the previous analysis made on node $\alpha$, and deduce that node $\beta$ has a neighboring node $\gamma$ with $d_{\gamma} < d_{\beta}$.
% (COMMENT: $\beta$ not being a cluster head and $\beta$ not belonging to any cluster is not the same statement!!! ANSWER(Di): I add some more words)
So far, when there is no cluster head identified, the unclustered nodes, \ie $\alpha$, $\beta$ form a linked list, where their connectivity degrees monotonically decrease.
But this list will not continue growing, because the minimum individual connectivity degree is zero, and the length of this list is upper bounded by the total number of nodes in the CRN.
An example of the formed node series is shown as Figure~\ref{lemma1}.

\begin{figure}[ht!]
  \centering
\includegraphics[width=0.6\linewidth]{lemma1.pdf}
% \includegraphics{figure1.pdf}
	\caption{The node series discussed in the proof of Theorem~\ref{clustering:theorem}, the deduction begins from node $\alpha$}
	\label{lemma1}
\end{figure}


In this example, node $\omega$ is at the tail of a list.
As $\omega$ does not have neighboring nodes with lower individual connectivity degree, $\omega$ becomes a cluster head.
Then $\omega$ incorporates all its one-hop neighbors (here we assume that every newly formed cluster has common channels), including the nodes which precede $\omega$ in the list.
The nodes which join a cluster set their individual connection degrees to $M$, which makes the node immediately precede in the list to become a cluster head.
In this way, cluster heads are generated from the tail to the head in the list, and every node in the list is in at least one cluster, which contradicts the assumption that $\alpha$ is not included in any cluster.

%If we see a secondary user \textit{becoming a cluster head}, or \textit{becoming a cluster member} as one step, as the length of the list of secondary users is not larger than $N$, there are $N$ steps for this scenario to form the initial clusters.

%we know that within at most $N$ steps, all the nodes belong to certain clusters. (COMMENT: No, we don't! Where was that shown?)
\end{proof}


%
\section{Proof of Theorem~\ref{theorem1}}
\label{proof_theorem1}
\begin{proof}
To prove the robust clustering problem is NP-hard, we reduce the \textit{maximum weighted k-set packing problem}, which is NP-hard when $k\geqslant 3$~\cite{Computers_a_Intractability}, to the the robust clustering problem to show the latter is at least as hard as the former.
Given a collection of sets of cardinality at most $k$ and with weights for each set, the maximum weighted packing problem is that of finding a collection of disjoint sets of maximum total weight.
The decision version of the weighted $k$-set packing problem is,
\begin{mydef}
\label{def_kset_packing}
Given a finite set $\mathcal{G}$ of non-negative integers where $\mathcal{G} \subsetneq \mathbb{N}$, and a collection of sets $\mathcal{Q}=\{S_1,S_2,\cdots,S_m\}$ where $S_i \subseteq \mathcal{G}$ and $\max(|S_i|)\geq 3$ for $1 \leq i \leq m$.
Every set $S$ in $\mathcal{Q}$ has a weight $\omega(S) \in \mathbb{N}^+$. 
%
The problem is to find a collection $\mathcal{I} \subseteq \mathcal{Q}$ such that $\mathcal{I}$ contains only the pairwise disjoint sets and the total weight of these sets is greater than a given positive number $\lambda$, i.e., $\sum_{\forall S \in \mathcal{I}} \omega(S) > \lambda$.
\end{mydef}


%First, we argue that robust clustering problem is in NP, since given a collection of clusters, a certifier can efficiently check that such clusters are pairwise disjoint, indeed contains all the CR nodes in the CRN $\mathcal{N}$ and the sum of $f(C)$ as shown in Definition~\ref{def_centralized_clustering} is greater than a certain value.

We will show that the weighted $k$-set packing problem $\leq_P$ CRN robust clustering problem.
Given an instance of the weighted $k$-set packing problem, \ie a collection of sets $\mathcal{Q}=\{S_1,S_2,\cdots,S_m\}$, where the set $S_i, i\in \{1,2,\ldots,m\}$ consists of positive integers.
There is an integer weight $\omega(S_i)$ for $S_i$, in the end an integer $\lambda$ completes the description of this instance.
We will construct an instance of a CRN robust clustering problem within polynomial time.
W.l.o.g. we let set $\cup_{i\in\{1, 2,\ldots, m\}}S_i = \{ 1, 2,\ldots , N \} = \mathcal{P}$.

We will construct the CRN and the clusters as follows:
For every set $S\in \mathcal{Q}$, there will be a corresponding cluster composed with CR nodes constructed.
For the set whose size is larger than 1, the IDs of the constructed CR nodes are identical with the elements in it, and we locate the CR nodes so that any two of them can communicate directly when common channels are available on them.
Besides, a set of channels with cardinality of $|\omega(S)|$ is allocated to all the CR nodes in this cluster, and the channels are on the spectrum band which is exclusive for this cluster.
For the set $S$ which contains only one element, \ie $S =\{t\}$ where $t\in\mathcal{P}$, a cluster composed with two CR nodes will be created.
In this case, one CR node's ID is $t$, the other CR node is the dummy node of the former and its ID is $t+N$.
A number of $|\omega(S)|$ channels from the exclusive spectrum band for this cluster are allocated to these two CR nodes.
Now we have constructed the clusters which correspond to all the sets in $\mathcal{Q}$.
Note that every CR node is allowed to form a singleton cluster by itself, although its common channels don't contribute to the sum of $f(C)$.
%In the end, we construct the singleton clusters, \ie for each element in $\mathcal{P}$, a corresponding singleton cluster is constructed.
%In particular, if the CR node has been constructed and has been in certain clusters already through the previous steps, the CR node with all the channels assigned to it constitute a singleton cluster.
%If there is an element in $\mathcal{P}$, which doesn't has a corresponding CR node yet, we simply construct this singleton cluster by adding that CR node, and assign it with a random number of channels from a exclusive spectrum band.
%We call the latter kind of clusters the \textit{auxiliary singleton clusters}.

Actually, all the constructed CR nodes can be assumed to locate in a very small area so that each CR node is within the transmission scope of every other CR node.
Note that in each constructed cluster, the CR nodes occupy the common channels which are exclusive to this cluster, this design of transformation eliminates the formation of the cluster which doesn't have a corresponding set in $\mathcal{Q}$.
The existence of the singleton clusters ensures that it is always possible to find out a group of clusters, which together constitute the whole CRN.
%Now we have completed a CRN and can claim that all the constructed clusters $C$ constitute the complete CRN network $\mathcal{N}$.

Now suppose there is a set of pairwise disjoint clusters which constitute the CRN $\mathcal{N}$, and the sum of $f(C)$ is greater than $\lambda$.
After removing the singleton clusters, we can easily find the natural association between the remaining clusters and the sets in $\mathcal{Q}$. 
The clusters in the CRN correspond to the sets in $\mathcal{Q}$ according to the mapping between the node IDs in the clusters and the elements in the sets.
In particular, the clusters which contain dummy CR nodes correspond to the sets which contain only one element.
Then the sum of the weights of the corresponding sets equals to the sum of $f(C)$ and thus greater than $\lambda$.




We have now shown that our algorithm solves the weighted $k$-set packing problem using a black box for the robust clustering problem. 
Since our construction takes polynomial time, we can conclude that the robust clustering problem is NP-hard.
%\begin{itemize}
%\item First, all the sets in the instance $\mathcal{I}$ are mapped sequentially to a group of clusters, \ie for a set $S\in\mathcal{I}$, the elements in $S$ are mapped to CR nodes which compose a cluster $C$, moreover, the resultant CR node's ID equals to the corresponding element in $\mathcal{S}$.
%This transformation takes $N$ steps.
%\item If $\mathcal{I}$ is not the solution because the intersection of two sets is not empty, the resultant clusters are not the solution to the clustering problem due to the overlapped clusters.
%When $\mathcal{I}$ contains only the disjoint sets, for each mapped cluster $C$, we assign the available channels for the nodes in $C$ so that the number of common channels in $C$ equals to the weight $\omega(S)$.
%This step of transformation takes $N*|\mathcal{K}|$ steps where $\mathcal{K}$ is the set of licensed channels.
%\item The resultant clusters are not an instance for the robust clustering problem yet because the clusters don't include all the CR nodes in the CRN, just as the instance $\mathcal{I}$ doesn't include all the elements in $\mathcal{G}$.
%We add the CR nodes besides the mapped clusters, which correspond to the elements in $\mathcal{G}\backslash\mathcal{I}$.
%We can randomly assign available channels on these newly added CR nodes, which do not contribute to the sum of the numbers of the common channels $f(C)$ as defined in~\ref{def_centralized_clustering} because they actually form singleton clusters and their cluster sizes are smaller than 2.
%This steps takes at most $N$ steps.
%
%
%\end{itemize}
%In this way, we change any instance of a weighted $k$-set packing problem into an instance of robust clustering.
%%The polynomial algorithm $\sigma$ consists of three steps.
%%\begin{itemize}
%%
%%\item First, the sets in the instance $\mathcal{I}$ are mapped sequentially to the clusters of CR nodes on a two-dimensional Euclidean plane, where the CR user ID is identical with the corresponding element's index.
%%
%%\item Second, for each mapped cluster $C$, we assign the channels for the nodes in $C$ so that $|K(C)|$ equals to the $\omega(S)$.
%%We can simply assign the first $|K(C)|$ channels to each CR node in $C$, without considering the possible mismatch when the same CR node appears in different clusters and is assigned with different channels.
%%
%%\end{itemize}
%%The number of steps is dependent on $\mathcal{I}$, which is between 1 and $N^2$.
%%
%Assume we have a robust clustering black box which checks whether the clustering instance meets the requirement, \ie clusters are not overlapping, and the sum of CCs of the clusters whose size is larger than 1 exceeds $\lambda$ or not.
%\begin{itemize}
%\item If \textit{yes} is said, then the total weight of the corresponding instance of the maximum weighted k-set packing problem is greater than $\lambda$.
%\item If the black box says \textit{no}, either due to overlapping clusters or the sum of CCs is smaller than $\lambda$, the corresponding instance of the packing problem is not a solution.
%\end{itemize}
%
%
%
%% The direction is wrong!!
%%When $\mathcal{I}$ is not an instance for weighted $k$-set packing problem due to the existence of joint sets, the corresponding clustering instance is not a successful cluster partition for the robust clustering problem, as there are overlapped clusters.
%%%
%%When the sets in an instance $\mathcal{I}$ for weighted $k$-set packing are disjoint, the sum of weights is identical to the total number of the CCs in the CRN which are mapped from $\mathcal{I'}$.
%%Thus, when a instance $\mathcal{I}$ for $k$-set packing problem is true (or false), \ie the sum of weights is greater than $\lambda$, then in the CRN which is mapped from $\mathcal{I'}$, the sum of the numbers of CCs of the clusters is greater (or smaller) than $\lambda$.
%
%Hence, the weighted $k$-set packing can be reduced to the robust clustering problem in CRN, thus the latter problem is as hard as the former thus is of NP-hard.
%%An example of the reduction is shown in Table~\ref{no_hard_proof_instance}.



\end{proof}



\bibliographystyle{IEEEtran}
\bibliography{../backmatter/myrefs}


%\ack This class file was developed by Sunrise Setting Ltd,
%Paignton, Devon, UK. Website:\\
%\href{http://www.sunrise-setting.co.uk}{\texttt{www.sunrise-setting.co.uk}}


\end{document}
